{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import csv\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/scott/scratch/Datasets/dsforce/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(root_dir, 'surveyExports/Survey17/Survey17_GR1_N0A_E_Sv_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(fname)\n",
    "#\n",
    "# Can't use pandas because of inconsistent columns. Attempting to do so generates this error:\n",
    "#\n",
    "# ParserError: Error tokenizing data. C error: Expected 2544 fields in line 3, saw 5977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_FIELD_TYPES = {\n",
    "    'Ping_index': int,\n",
    "    'Distance_gps': float,\n",
    "    'Distance_vl': float,\n",
    "    'Ping_date': str,\n",
    "    'Ping_time': str,\n",
    "    'Ping_milliseconds': float,\n",
    "    'Latitude': float,\n",
    "    'Longitude': float,\n",
    "    'Depth_start': float,\n",
    "    'Depth_stop': float,\n",
    "    'Range_start': float,\n",
    "    'Range_stop': float,\n",
    "    'Sample_count': int,\n",
    "}\n",
    "\n",
    "\n",
    "def survey_reader(fname):\n",
    "    '''\n",
    "    Creates a generator which iterates through a survey csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname: str\n",
    "        Path to survey CSV file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    generator\n",
    "        Yields a tupule of `(metadata, data)`, where metadata is a dict,\n",
    "        and data is a `numpy.ndarray`. Each yield corresponds to a single\n",
    "        row in the data. Every row (except for the header) is yielded.\n",
    "    '''\n",
    "    metadata_header = []\n",
    "    with open(fname, 'r', encoding='utf-8-sig') as hf:\n",
    "        for i_row, row in enumerate(csv.reader(hf)):\n",
    "            row = [entry.strip() for entry in row]\n",
    "            if i_row == 0:\n",
    "                metadata_header = row\n",
    "                continue;\n",
    "            metadata = row[:len(metadata_header)]\n",
    "            metadata_d = OrderedDict()\n",
    "            for k, v in zip(metadata_header, metadata):\n",
    "                if k in SURVEY_FIELD_TYPES:\n",
    "                    metadata_d[k] = SURVEY_FIELD_TYPES[k](v)\n",
    "                else:\n",
    "                    metadata_d[k] = v\n",
    "            data = np.array([float(x) for x in row[len(metadata_header):]])\n",
    "            yield metadata_d, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(filename):\n",
    "    '''\n",
    "    Count the number of lines in a file.\n",
    "\n",
    "    Credit: https://stackoverflow.com/a/27518377\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to file.\n",
    "\n",
    "    Returns\n",
    "    int\n",
    "        Number of lines in file.\n",
    "    '''\n",
    "    f = open(filename)                  \n",
    "    lines = 0\n",
    "    buf_size = 1024 * 1024\n",
    "    read_f = f.read  # loop optimization\n",
    "\n",
    "    buf = read_f(buf_size)\n",
    "    while buf:\n",
    "        lines += buf.count('\\n')\n",
    "        buf = read_f(buf_size)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta, data in survey_reader(fname):\n",
    "    print(meta, data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lines(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survey_loader(fname, skip_lines=1):\n",
    "    '''\n",
    "    Loads an entire survey CSV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Path to survey CSV file.\n",
    "    skip_lines : int, optional\n",
    "        Number of initial entries to skip. Default is 1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Timestamps for each row, in seconds. Note: not corrected for timezone.\n",
    "    numpy.ndarray\n",
    "        Depth of each column, in metres.\n",
    "    numpy.ndarray\n",
    "        Survey signal (echo strength, units unknown).\n",
    "    '''\n",
    "\n",
    "    # We remove one from the line count because of the header\n",
    "    # which is excluded from output\n",
    "    n_lines = count_lines(fname) - 1\n",
    "    n_distances = 0\n",
    "    depth_start = None\n",
    "    depth_stop = None\n",
    "\n",
    "    # Initialise output array\n",
    "    for i_line, (meta, row) in enumerate(survey_reader(fname)):\n",
    "        if i_line < skip_lines:\n",
    "            continue\n",
    "        n_depths = len(row)\n",
    "        depth_start = meta['Depth_start']\n",
    "        depth_stop = meta['Depth_stop']\n",
    "        break\n",
    "\n",
    "    data = np.empty((n_lines - skip_lines, n_depths))\n",
    "    timestamps = np.empty((n_lines - skip_lines))\n",
    "    depths = np.linspace(depth_start, depth_stop, n_depths)\n",
    "\n",
    "    for i_line, (meta, row) in enumerate(survey_reader(fname)):\n",
    "        if i_line < skip_lines:\n",
    "            continue\n",
    "        i_entry = i_line - skip_lines\n",
    "        data[i_entry, :] = row\n",
    "        timestamps[i_entry] = datetime.datetime.strptime(\n",
    "            '{}T{}.{:06d}'.format(\n",
    "                meta['Ping_date'],\n",
    "                meta['Ping_time'],\n",
    "                int(1000 * float(meta['Ping_milliseconds'])),\n",
    "            ),\n",
    "            '%Y-%m-%dT%H:%M:%S.%f',\n",
    "        ).timestamp()\n",
    "\n",
    "    # Turn NaNs into NaNs (instead of extremely negative number)\n",
    "    data[data < -1e6] = np.nan\n",
    "\n",
    "    return timestamps, depths, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, depths, signals = survey_loader(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.reshape(signals[::10, ::10], -1), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(signals.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evl_reader(fname):\n",
    "    '''\n",
    "    EVL file reader\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Path to .evl file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    generator\n",
    "        A generator which yields the timestamp (in seconds) and depth (in metres)\n",
    "        for each entry. Note that the timestamp is not corrected for timezone\n",
    "        (so make sure your timezones are internally consistent).\n",
    "    '''\n",
    "    with open(fname, 'r') as hf:\n",
    "        continuance = True\n",
    "        for i_row, row in enumerate(csv.reader(hf, delimiter=' ')):\n",
    "            if i_row == 0:\n",
    "                continue\n",
    "            if len(row) < 4:\n",
    "                if not continuance:\n",
    "                    raise ValueError('Trying to skip data after parsing began')\n",
    "                continue\n",
    "            continuance = False\n",
    "\n",
    "            timestamp = datetime.datetime.strptime(\n",
    "                row[0] + 'T' + row[1],\n",
    "                '%Y%m%dT%H%M%S%f',\n",
    "            ).timestamp()\n",
    "\n",
    "            if len(row[2]) > 0:\n",
    "                raise ValueError('row[2] was non-empty: {}'.format(row[2]))\n",
    "\n",
    "            yield timestamp, float(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evl_loader(fname):\n",
    "    '''\n",
    "    EVL file loader\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Path to .evl file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Timestamps, in seconds.\n",
    "    numpy.ndarary\n",
    "        Depth, in metres.\n",
    "    '''\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    for timestamp, value in evl_reader(fname):\n",
    "        timestamps.append(timestamp)\n",
    "        values.append(value)\n",
    "    return np.array(timestamps), np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_fname = os.path.join(root_dir, 'surveyExports/Survey17/Survey17_GR1_N0A_E_bottom.evl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, v in evl_reader(bottom_fname):\n",
    "    print(t, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evl_loader(bottom_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fname = os.path.join(root_dir, 'surveyExports/Survey17/Survey17_GR1_N0A_E_turbulence.evl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evl_loader(top_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "\n",
    "t_bottom, d_bottom = evl_loader(bottom_fname)\n",
    "t_top, d_top = evl_loader(top_fname)\n",
    "\n",
    "plt.plot(t_bottom, -d_bottom, 'b')\n",
    "plt.plot(t_top, -d_top, 'c')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

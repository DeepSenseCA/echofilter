{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import datetime\n",
        "import os\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_dir = \"/media/scott/scratch/Datasets/dsforce/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fname = os.path.join(root_dir, \"surveyExports/Survey17/Survey17_GR1_N0A_E_Sv_raw.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = pd.read_csv(fname)\n",
        "#\n",
        "# Can't use pandas because of inconsistent columns. Attempting to do so generates this error:\n",
        "#\n",
        "# ParserError: Error tokenizing data. C error: Expected 2544 fields in line 3, saw 5977"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SURVEY_FIELD_TYPES = {\n",
        "    \"Ping_index\": int,\n",
        "    \"Distance_gps\": float,\n",
        "    \"Distance_vl\": float,\n",
        "    \"Ping_date\": str,\n",
        "    \"Ping_time\": str,\n",
        "    \"Ping_milliseconds\": float,\n",
        "    \"Latitude\": float,\n",
        "    \"Longitude\": float,\n",
        "    \"Depth_start\": float,\n",
        "    \"Depth_stop\": float,\n",
        "    \"Range_start\": float,\n",
        "    \"Range_stop\": float,\n",
        "    \"Sample_count\": int,\n",
        "}\n",
        "\n",
        "\n",
        "def survey_reader(fname):\n",
        "    \"\"\"\n",
        "    Creates a generator which iterates through a survey csv file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fname: str\n",
        "        Path to survey CSV file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    generator\n",
        "        Yields a tupule of `(metadata, data)`, where metadata is a dict,\n",
        "        and data is a `numpy.ndarray`. Each yield corresponds to a single\n",
        "        row in the data. Every row (except for the header) is yielded.\n",
        "    \"\"\"\n",
        "    metadata_header = []\n",
        "    with open(fname, \"r\", encoding=\"utf-8-sig\") as hf:\n",
        "        for i_row, row in enumerate(csv.reader(hf)):\n",
        "            row = [entry.strip() for entry in row]\n",
        "            if i_row == 0:\n",
        "                metadata_header = row\n",
        "                continue\n",
        "            metadata = row[: len(metadata_header)]\n",
        "            metadata_d = OrderedDict()\n",
        "            for k, v in zip(metadata_header, metadata):\n",
        "                if k in SURVEY_FIELD_TYPES:\n",
        "                    metadata_d[k] = SURVEY_FIELD_TYPES[k](v)\n",
        "                else:\n",
        "                    metadata_d[k] = v\n",
        "            data = np.array([float(x) for x in row[len(metadata_header) :]])\n",
        "            yield metadata_d, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_lines(filename):\n",
        "    \"\"\"\n",
        "    Count the number of lines in a file.\n",
        "\n",
        "    Credit: https://stackoverflow.com/a/27518377\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Path to file.\n",
        "\n",
        "    Returns\n",
        "    int\n",
        "        Number of lines in file.\n",
        "    \"\"\"\n",
        "    f = open(filename)\n",
        "    lines = 0\n",
        "    buf_size = 1024 * 1024\n",
        "    read_f = f.read  # loop optimization\n",
        "\n",
        "    buf = read_f(buf_size)\n",
        "    while buf:\n",
        "        lines += buf.count(\"\\n\")\n",
        "        buf = read_f(buf_size)\n",
        "\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for meta, data in survey_reader(fname):\n",
        "    print(meta, data)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_lines(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def survey_loader(fname, skip_lines=1, warn_row_overflow=True):\n",
        "    \"\"\"\n",
        "    Loads an entire survey CSV.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fname : str\n",
        "        Path to survey CSV file.\n",
        "    skip_lines : int, optional\n",
        "        Number of initial entries to skip. Default is 1.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray\n",
        "        Timestamps for each row, in seconds. Note: not corrected for timezone.\n",
        "    numpy.ndarray\n",
        "        Depth of each column, in metres.\n",
        "    numpy.ndarray\n",
        "        Survey signal (echo strength, units unknown).\n",
        "    \"\"\"\n",
        "\n",
        "    # We remove one from the line count because of the header\n",
        "    # which is excluded from output\n",
        "    n_lines = count_lines(fname) - 1\n",
        "    # n_distances = 0\n",
        "    depth_start = None\n",
        "    depth_stop = None\n",
        "\n",
        "    # Initialise output array\n",
        "    for i_line, (meta, row) in enumerate(survey_reader(fname)):\n",
        "        if i_line < skip_lines:\n",
        "            continue\n",
        "        n_depths = len(row)\n",
        "        depth_start = meta[\"Depth_start\"]\n",
        "        depth_stop = meta[\"Depth_stop\"]\n",
        "        break\n",
        "\n",
        "    data = np.empty((n_lines - skip_lines, n_depths))\n",
        "    timestamps = np.empty((n_lines - skip_lines))\n",
        "    depths = np.linspace(depth_start, depth_stop, n_depths)\n",
        "\n",
        "    for i_line, (meta, row) in enumerate(survey_reader(fname)):\n",
        "        if i_line < skip_lines:\n",
        "            continue\n",
        "        i_entry = i_line - skip_lines\n",
        "        if warn_row_overflow and len(row) > n_depths:\n",
        "            print(\n",
        "                \"Row {} of {} exceeds expected n_depths of {} with {}\".format(\n",
        "                    i_line, fname, n_depths, len(row)\n",
        "                )\n",
        "            )\n",
        "        data[i_entry, :] = row[:n_depths]\n",
        "        timestamps[i_entry] = datetime.datetime.strptime(\n",
        "            \"{}T{}.{:06d}\".format(\n",
        "                meta[\"Ping_date\"],\n",
        "                meta[\"Ping_time\"],\n",
        "                int(1000 * float(meta[\"Ping_milliseconds\"])),\n",
        "            ),\n",
        "            \"%Y-%m-%dT%H:%M:%S.%f\",\n",
        "        ).timestamp()\n",
        "\n",
        "    # Turn NaNs into NaNs (instead of extremely negative number)\n",
        "    data[data < -1e6] = np.nan\n",
        "\n",
        "    return timestamps, depths, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fname2 = os.path.join(\n",
        "    root_dir, \"surveyExports\", \"Survey03/Survey03_GR2_S1A_survey3_Sv_raw.csv\"\n",
        ")\n",
        "timestamps, depths, signals = survey_loader(fname2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps, depths, signals = survey_loader(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(signals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(signals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.prod(signals.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(np.reshape(signals, -1), bins=100, density=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(signals.T)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evl_reader(fname):\n",
        "    \"\"\"\n",
        "    EVL file reader\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fname : str\n",
        "        Path to .evl file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    generator\n",
        "        A generator which yields the timestamp (in seconds) and depth (in metres)\n",
        "        for each entry. Note that the timestamp is not corrected for timezone\n",
        "        (so make sure your timezones are internally consistent).\n",
        "    \"\"\"\n",
        "    with open(fname, \"r\") as hf:\n",
        "        continuance = True\n",
        "        for i_row, row in enumerate(csv.reader(hf, delimiter=\" \")):\n",
        "            if i_row == 0:\n",
        "                continue\n",
        "            if len(row) < 4:\n",
        "                if not continuance:\n",
        "                    raise ValueError(\"Trying to skip data after parsing began\")\n",
        "                continue\n",
        "            continuance = False\n",
        "\n",
        "            timestamp = datetime.datetime.strptime(\n",
        "                row[0] + \"T\" + row[1],\n",
        "                \"%Y%m%dT%H%M%S%f\",\n",
        "            ).timestamp()\n",
        "\n",
        "            if len(row[2]) > 0:\n",
        "                raise ValueError(\"row[2] was non-empty: {}\".format(row[2]))\n",
        "\n",
        "            yield timestamp, float(row[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evl_loader(fname):\n",
        "    \"\"\"\n",
        "    EVL file loader\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fname : str\n",
        "        Path to .evl file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray\n",
        "        Timestamps, in seconds.\n",
        "    numpy.ndarary\n",
        "        Depth, in metres.\n",
        "    \"\"\"\n",
        "    timestamps = []\n",
        "    values = []\n",
        "    for timestamp, value in evl_reader(fname):\n",
        "        timestamps.append(timestamp)\n",
        "        values.append(value)\n",
        "    return np.array(timestamps), np.array(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bottom_fname = os.path.join(\n",
        "    root_dir, \"surveyExports/Survey17/Survey17_GR1_N0A_E_bottom.evl\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for t, v in evl_reader(bottom_fname):\n",
        "    print(t, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evl_loader(bottom_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_fname = os.path.join(\n",
        "    root_dir, \"surveyExports/Survey17/Survey17_GR1_N0A_E_turbulence.evl\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evl_loader(top_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "\n",
        "t_bottom, d_bottom = evl_loader(bottom_fname)\n",
        "t_top, d_top = evl_loader(top_fname)\n",
        "\n",
        "plt.plot(t_bottom, -d_bottom, \"b\")\n",
        "plt.plot(t_top, -d_top, \"c\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_transect_data(survey, transect_name, root_dir):\n",
        "\n",
        "    dirname = os.path.join(root_dir, \"surveyExports\", \"Survey\" + str(survey))\n",
        "    raw_fname = os.path.join(\n",
        "        dirname, \"Survey{}_{}_Sv_raw.csv\".format(survey, transect_name)\n",
        "    )\n",
        "    bot_fname = os.path.join(\n",
        "        dirname, \"Survey{}_{}_bottom.evl\".format(survey, transect_name)\n",
        "    )\n",
        "    top_fname = os.path.join(\n",
        "        dirname, \"Survey{}_{}_turbulence.evl\".format(survey, transect_name)\n",
        "    )\n",
        "\n",
        "    timestamps, depths, signals = survey_loader(raw_fname)\n",
        "    t_bottom, d_bottom = evl_loader(bot_fname)\n",
        "    t_top, d_top = evl_loader(top_fname)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "    plt.plot(t_bottom, -d_bottom, \"b\")\n",
        "    plt.plot(t_top, -d_top, \"c\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey = 17\n",
        "transect_name = \"GR1_N0A_E\"\n",
        "\n",
        "plot_transect_data(survey, transect_name, root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey = 17\n",
        "transect_name = \"GR1_N2W_E\"\n",
        "\n",
        "plot_transect_data(survey, transect_name, root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey = 17\n",
        "transect_name = \"GR1_N3A_F\"\n",
        "\n",
        "plot_transect_data(survey, transect_name, root_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

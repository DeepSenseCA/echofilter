{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echofilter.rawloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = '/media/scott/scratch/Datasets/dsforce'\n",
    "ROOT_DATA_DIR = '/data/dsforce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transect_data(transect_pth, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR):\n",
    "\n",
    "    dirname = os.path.join(root_data_dir, dataset)\n",
    "    raw_fname = os.path.join(dirname, transect_pth + '_Sv_raw.csv')\n",
    "    bot_fname = os.path.join(dirname, transect_pth + '_bottom.evl')\n",
    "    top_fname = os.path.join(dirname, transect_pth + '_turbulence.evl')\n",
    "\n",
    "    timestamps, depths, signals = transect_loader(raw_fname)\n",
    "    t_bot, d_bot = evl_loader(bot_fname)\n",
    "    t_top, d_top = evl_loader(top_fname)\n",
    "\n",
    "    return timestamps, depths, signals, np.interp(timestamps, t_top, d_top), np.interp(timestamps, t_bot, d_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transect_data2(survey, transect_name, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR):\n",
    "\n",
    "    return load_transect_data(\n",
    "        os.path.join('Survey{}'.format(survey), 'Survey{}_{}'.format(survey, transect_name)),\n",
    "        dataset=dataset,\n",
    "        root_data_dir=root_data_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transect_data(transect_pth, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR):\n",
    "\n",
    "    timestamps, depths, signals, d_top, d_bot = load_transect_data(transect_pth, dataset, root_data_dir)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "    plt.plot(timestamps, -d_bot, 'b')\n",
    "    plt.plot(timestamps, -d_top, 'c')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transect_data2(survey, transect_name, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR):\n",
    "\n",
    "    timestamps, depths, signals, d_top, d_bot = load_transect_data2(survey, transect_name, dataset, root_data_dir)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "    plt.plot(timestamps, -d_bot, 'b')\n",
    "    plt.plot(timestamps, -d_top, 'c')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_data('Survey17/Survey17_GR1_N0A_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 17\n",
    "transect_name = 'GR1_N0A_E'\n",
    "plot_transect_data2(survey, transect_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_data(\n",
    "        partition, dataset='surveyExports', partitioning_version='firstpass', root_data_dir=ROOT_DATA_DIR,\n",
    "    ):\n",
    "\n",
    "    dirname = os.path.join(root_data_dir, dataset, 'sets', partitioning_version)\n",
    "    fname_partition = os.path.join(dirname, partition + '.txt')\n",
    "    fname_header = os.path.join(dirname, 'header' + '.txt')\n",
    "\n",
    "    with open(fname_header, 'r') as hf:\n",
    "        for row in csv.reader(hf):\n",
    "            header = [entry.strip() for entry in row]\n",
    "            break\n",
    "\n",
    "    df = pd.read_csv(fname_partition, header=None, names=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_partition_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_list(\n",
    "        partition,\n",
    "        dataset='surveyExports',\n",
    "        full_path=False,\n",
    "        partitioning_version='firstpass',\n",
    "        root_data_dir=ROOT_DATA_DIR,\n",
    "    ):\n",
    "    df = get_partition_data(\n",
    "        partition,\n",
    "        dataset=dataset,\n",
    "        partitioning_version=partitioning_version,\n",
    "        root_data_dir=root_data_dir,\n",
    "    )\n",
    "    fnames = df['Filename']\n",
    "    fnames = [os.path.join(f.split('_')[0], f.strip().replace('_Sv_raw.csv', '')) for f in fnames]\n",
    "    if full_path:\n",
    "        fnames = [os.path.join(root_data_dir, dataset, f) for f in fnames]\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_partition_list('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_partition_list('train', full_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<40s}{:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in sorted(get_partition_list('train', full_path=True)):\n",
    "    fname = fname + '_bottom.evl'\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print(\n",
    "        '{:<40s}{:6.1f} {:6.1f}  {}'\n",
    "        .format(os.path.split(fname)[1], min(depths), max(depths), '*' if max(depths) > 62 else '')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<40s}{:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in sorted(get_partition_list('validate', full_path=True)):\n",
    "    fname = fname + '_bottom.evl'\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print(\n",
    "        '{:<40s}{:6.1f} {:6.1f}  {}'\n",
    "        .format(os.path.split(fname)[1], min(depths), max(depths), '*' if max(depths) > 62 else '')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<40s}{:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in sorted(get_partition_list('test', full_path=True)):\n",
    "    fname = fname + '_bottom.evl'\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print(\n",
    "        '{:<40s}{:6.1f} {:6.1f}  {}'\n",
    "        .format(os.path.split(fname)[1], min(depths), max(depths), '*' if max(depths) > 62 else '')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<40s}{:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in sorted(get_partition_list('leaveout', full_path=True)):\n",
    "    fname = fname + '_bottom.evl'\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print(\n",
    "        '{:<40s}{:6.1f} {:6.1f}  {}'\n",
    "        .format(os.path.split(fname)[1], min(depths), max(depths), '*' if max(depths) > 62 else '')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One weird survey\n",
    "plot_transect_data('Survey17/Survey17_GR4_S3A_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_data('Survey17/Survey17_GR1_S3W_F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_data('Survey03/Survey03_GR2_S1A_survey3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40, 62, 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_data('Survey17/Survey17_GR1_S3W_F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pth = 'Survey17/Survey17_GR1_S3W_F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, depths, signals, d_top, d_bot = load_transect_data(\n",
    "    transect_pth, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps[:128], -depths[:2000], signals[:128, :2000].T)\n",
    "plt.plot(timestamps[:128], -d_bot[:128], 'b')\n",
    "plt.plot(timestamps[:128], -d_top[:128], 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwn_sig = signals[:128, :2000].reshape(128, 200, 10).mean(-1).reshape(128, 200)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps[:128], -depths[:2000:10], dwn_sig.T)\n",
    "plt.plot(timestamps[:128], -d_bot[:128], 'b')\n",
    "plt.plot(timestamps[:128], -d_top[:128], 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_transect(transect_pth, dataset='surveyExports', max_depth=100, shard_len=128, root_data_dir=ROOT_DATA_DIR):\n",
    "    root_shard_dir = os.path.join(root_data_dir, dataset + '_sharded')\n",
    "    timestamps, depths, signals, d_top, d_bot = load_transect_data(transect_pth, dataset, root_data_dir)\n",
    "    depth_mask = depths <= 100\n",
    "    indices = range(128, signals.shape[0], 128)\n",
    "    dirname = os.path.join(root_shard_dir, transect_pth)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    with open(os.path.join(dirname, 'shard_size.txt'), 'w') as hf:\n",
    "        print('{},{}'.format(len(timestamps), shard_len), file=hf)\n",
    "    for i, (ts_i, sig_i, top_i, bot_i) in enumerate(\n",
    "            zip(\n",
    "                np.split(timestamps, indices),\n",
    "                np.split(np.single(signals[:, depth_mask]), indices),\n",
    "                np.split(np.single(d_top), indices),\n",
    "                np.split(np.single(d_bot), indices),\n",
    "            )\n",
    "    ):\n",
    "        os.makedirs(os.path.join(dirname, str(i)), exist_ok=True)\n",
    "        for obj, fname in (\n",
    "                (depths[depth_mask], 'depths'), (ts_i, 'timestamps'),\n",
    "                (sig_i, 'Sv'), (top_i, 'top'), (bot_i, 'bottom')):\n",
    "            obj.dump(os.path.join(dirname, str(i), fname + '.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transect_from_shards(\n",
    "        transect_pth, i1=0, i2=None, dataset='surveyExports', root_data_dir=ROOT_DATA_DIR\n",
    "    ):\n",
    "    root_shard_dir = os.path.join(root_data_dir, dataset + '_sharded')\n",
    "    dirname = os.path.join(root_shard_dir, transect_pth)\n",
    "    with open(os.path.join(dirname, 'shard_size.txt'), 'r') as f:\n",
    "        n_timestamps, shard_len = f.readline().strip().split(',')\n",
    "        n_timestamps = int(n_timestamps)\n",
    "        shard_len = int(shard_len)\n",
    "    if i2 is None: i2 = n_timestamps\n",
    "    j1 = max(0, int(i1 / shard_len))\n",
    "    j2 = int(min(i2, n_timestamps - 1) / shard_len)\n",
    "\n",
    "    depths = np.load(os.path.join(dirname, str(j1), 'depths.npy'), allow_pickle=True)\n",
    "    def load_shard(fname):\n",
    "        return np.concatenate([\n",
    "            np.load(os.path.join(dirname, str(j), fname + '.npy'), allow_pickle=True)\n",
    "            for j in range(j1, j2+1)\n",
    "        ])[(i1 - j1 * shard_len) : (i2 - j1 * shard_len)]\n",
    "    timestamps = load_shard('timestamps')\n",
    "    signals = load_shard('Sv')\n",
    "    d_top = load_shard('top')\n",
    "    d_bot = load_shard('bottom')\n",
    "\n",
    "    return timestamps, depths, signals, d_top, d_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_transect(transect_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = load_transect_from_shards(transect_pth)\n",
    "for io in o:\n",
    "    print(io.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = load_transect_from_shards(transect_pth, 200, 500)\n",
    "for io in o:\n",
    "    print(io.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, depths, signals, d_top, d_bot = load_transect_from_shards(transect_pth, 100, 800)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "plt.plot(timestamps, -d_bot, 'b')\n",
    "plt.plot(timestamps, -d_top, 'c')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

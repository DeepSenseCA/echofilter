{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from echofilter.raw.loader import evl_loader, transect_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_DATA_DIR = \"/media/scott/scratch/Datasets/dsforce\"\n",
        "ROOT_DATA_DIR = \"/data/dsforce\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_transect_data(\n",
        "    transect_pth, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        "):\n",
        "\n",
        "    dirname = os.path.join(root_data_dir, dataset)\n",
        "    raw_fname = os.path.join(dirname, transect_pth + \"_Sv_raw.csv\")\n",
        "    bot_fname = os.path.join(dirname, transect_pth + \"_bottom.evl\")\n",
        "    top_fname = os.path.join(dirname, transect_pth + \"_turbulence.evl\")\n",
        "\n",
        "    timestamps, depths, signals = transect_loader(raw_fname)\n",
        "    t_bot, d_bot = evl_loader(bot_fname)\n",
        "    t_top, d_top = evl_loader(top_fname)\n",
        "\n",
        "    return (\n",
        "        timestamps,\n",
        "        depths,\n",
        "        signals,\n",
        "        np.interp(timestamps, t_top, d_top),\n",
        "        np.interp(timestamps, t_bot, d_bot),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_transect_data2(\n",
        "    survey, transect_name, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        "):\n",
        "\n",
        "    return load_transect_data(\n",
        "        os.path.join(\n",
        "            \"Survey{}\".format(survey), \"Survey{}_{}\".format(survey, transect_name)\n",
        "        ),\n",
        "        dataset=dataset,\n",
        "        root_data_dir=root_data_dir,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_transect_data(\n",
        "    transect_pth, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        "):\n",
        "\n",
        "    timestamps, depths, signals, d_top, d_bot = load_transect_data(\n",
        "        transect_pth, dataset, root_data_dir\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "    plt.plot(timestamps, -d_bot, \"b\")\n",
        "    plt.plot(timestamps, -d_top, \"c\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_transect_data2(\n",
        "    survey, transect_name, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        "):\n",
        "\n",
        "    timestamps, depths, signals, d_top, d_bot = load_transect_data2(\n",
        "        survey, transect_name, dataset, root_data_dir\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "    plt.plot(timestamps, -d_bot, \"b\")\n",
        "    plt.plot(timestamps, -d_top, \"c\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_transect_data(\"Survey17/Survey17_GR1_N0A_E\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "survey = 17\n",
        "transect_name = \"GR1_N0A_E\"\n",
        "plot_transect_data2(survey, transect_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_partition_data(\n",
        "    partition,\n",
        "    dataset=\"surveyExports\",\n",
        "    partitioning_version=\"firstpass\",\n",
        "    root_data_dir=ROOT_DATA_DIR,\n",
        "):\n",
        "\n",
        "    dirname = os.path.join(root_data_dir, dataset, \"sets\", partitioning_version)\n",
        "    fname_partition = os.path.join(dirname, partition + \".txt\")\n",
        "    fname_header = os.path.join(dirname, \"header\" + \".txt\")\n",
        "\n",
        "    with open(fname_header, \"r\") as hf:\n",
        "        for row in csv.reader(hf):\n",
        "            header = [entry.strip() for entry in row]\n",
        "            break\n",
        "\n",
        "    df = pd.read_csv(fname_partition, header=None, names=header)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_partition_data(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_partition_list(\n",
        "    partition,\n",
        "    dataset=\"surveyExports\",\n",
        "    full_path=False,\n",
        "    partitioning_version=\"firstpass\",\n",
        "    root_data_dir=ROOT_DATA_DIR,\n",
        "):\n",
        "    df = get_partition_data(\n",
        "        partition,\n",
        "        dataset=dataset,\n",
        "        partitioning_version=partitioning_version,\n",
        "        root_data_dir=root_data_dir,\n",
        "    )\n",
        "    fnames = df[\"Filename\"]\n",
        "    fnames = [\n",
        "        os.path.join(f.split(\"_\")[0], f.strip().replace(\"_Sv_raw.csv\", \"\"))\n",
        "        for f in fnames\n",
        "    ]\n",
        "    if full_path:\n",
        "        fnames = [os.path.join(root_data_dir, dataset, f) for f in fnames]\n",
        "    return fnames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_partition_list(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_partition_list(\"train\", full_path=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"{:<40s}{:>6s} {:>6s}\".format(\"Filename\", \"Min D\", \"Max D\"))\n",
        "\n",
        "for fname in sorted(get_partition_list(\"train\", full_path=True)):\n",
        "    fname = fname + \"_bottom.evl\"\n",
        "    try:\n",
        "        depths = evl_loader(fname)[1]\n",
        "    except Exception:\n",
        "        continue\n",
        "    print(\n",
        "        \"{:<40s}{:6.1f} {:6.1f}  {}\".format(\n",
        "            os.path.split(fname)[1],\n",
        "            min(depths),\n",
        "            max(depths),\n",
        "            \"*\" if max(depths) > 62 else \"\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"{:<40s}{:>6s} {:>6s}\".format(\"Filename\", \"Min D\", \"Max D\"))\n",
        "\n",
        "for fname in sorted(get_partition_list(\"validate\", full_path=True)):\n",
        "    fname = fname + \"_bottom.evl\"\n",
        "    try:\n",
        "        depths = evl_loader(fname)[1]\n",
        "    except Exception:\n",
        "        continue\n",
        "    print(\n",
        "        \"{:<40s}{:6.1f} {:6.1f}  {}\".format(\n",
        "            os.path.split(fname)[1],\n",
        "            min(depths),\n",
        "            max(depths),\n",
        "            \"*\" if max(depths) > 62 else \"\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"{:<40s}{:>6s} {:>6s}\".format(\"Filename\", \"Min D\", \"Max D\"))\n",
        "\n",
        "for fname in sorted(get_partition_list(\"test\", full_path=True)):\n",
        "    fname = fname + \"_bottom.evl\"\n",
        "    try:\n",
        "        depths = evl_loader(fname)[1]\n",
        "    except Exception:\n",
        "        continue\n",
        "    print(\n",
        "        \"{:<40s}{:6.1f} {:6.1f}  {}\".format(\n",
        "            os.path.split(fname)[1],\n",
        "            min(depths),\n",
        "            max(depths),\n",
        "            \"*\" if max(depths) > 62 else \"\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"{:<40s}{:>6s} {:>6s}\".format(\"Filename\", \"Min D\", \"Max D\"))\n",
        "\n",
        "for fname in sorted(get_partition_list(\"leaveout\", full_path=True)):\n",
        "    fname = fname + \"_bottom.evl\"\n",
        "    try:\n",
        "        depths = evl_loader(fname)[1]\n",
        "    except Exception:\n",
        "        continue\n",
        "    print(\n",
        "        \"{:<40s}{:6.1f} {:6.1f}  {}\".format(\n",
        "            os.path.split(fname)[1],\n",
        "            min(depths),\n",
        "            max(depths),\n",
        "            \"*\" if max(depths) > 62 else \"\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One weird survey\n",
        "plot_transect_data(\"Survey17/Survey17_GR4_S3A_E\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"{:<40s}{:>6s} {:>6s}\".format(\"Filename\", \"Min D\", \"Max D\"))\n",
        "\n",
        "for fname in sorted(get_partition_list(\"train\", full_path=True)):\n",
        "    fname = fname + \"_turbulence.evl\"\n",
        "    try:\n",
        "        depths = evl_loader(fname)[1]\n",
        "    except Exception:\n",
        "        continue\n",
        "    print(\n",
        "        \"{:<40s}{:6.1f} {:6.1f}  {}\".format(\n",
        "            os.path.split(fname)[1],\n",
        "            min(depths),\n",
        "            max(depths),\n",
        "            \"*\" if max(depths) > 62 else \"\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_transect_data(\"Survey17/Survey17_GR4_N5A_E\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_transect_data(\"Survey17/Survey17_GR1_S3W_F\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_transect_data(\"Survey03/Survey03_GR2_S1A_survey3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "40, 62, 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_transect_data(\"Survey17/Survey17_GR1_S3W_F\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transect_pth = \"Survey17/Survey17_GR1_S3W_F\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps, depths, signals, d_top, d_bot = load_transect_data(\n",
        "    transect_pth, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.pcolormesh(timestamps[:128], -depths[:2000], signals[:128, :2000].T)\n",
        "plt.plot(timestamps[:128], -d_bot[:128], \"b\")\n",
        "plt.plot(timestamps[:128], -d_top[:128], \"c\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dwn_sig = signals[:128, :2000].reshape(128, 200, 10).mean(-1).reshape(128, 200)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.pcolormesh(timestamps[:128], -depths[:2000:10], dwn_sig.T)\n",
        "plt.plot(timestamps[:128], -d_bot[:128], \"b\")\n",
        "plt.plot(timestamps[:128], -d_top[:128], \"c\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shard_transect(\n",
        "    transect_pth,\n",
        "    dataset=\"surveyExports\",\n",
        "    max_depth=100,\n",
        "    shard_len=128,\n",
        "    root_data_dir=ROOT_DATA_DIR,\n",
        "):\n",
        "    root_shard_dir = os.path.join(root_data_dir, dataset + \"_sharded\")\n",
        "    timestamps, depths, signals, d_top, d_bot = load_transect_data(\n",
        "        transect_pth, dataset, root_data_dir\n",
        "    )\n",
        "    depth_mask = depths <= 100\n",
        "    indices = range(128, signals.shape[0], 128)\n",
        "    dirname = os.path.join(root_shard_dir, transect_pth)\n",
        "    os.makedirs(dirname, exist_ok=True)\n",
        "    with open(os.path.join(dirname, \"shard_size.txt\"), \"w\") as hf:\n",
        "        print(\"{},{}\".format(len(timestamps), shard_len), file=hf)\n",
        "    for i, (ts_i, sig_i, top_i, bot_i) in enumerate(\n",
        "        zip(\n",
        "            np.split(timestamps, indices),\n",
        "            np.split(np.single(signals[:, depth_mask]), indices),\n",
        "            np.split(np.single(d_top), indices),\n",
        "            np.split(np.single(d_bot), indices),\n",
        "        )\n",
        "    ):\n",
        "        os.makedirs(os.path.join(dirname, str(i)), exist_ok=True)\n",
        "        for obj, fname in (\n",
        "            (depths[depth_mask], \"depths\"),\n",
        "            (ts_i, \"timestamps\"),\n",
        "            (sig_i, \"Sv\"),\n",
        "            (top_i, \"top\"),\n",
        "            (bot_i, \"bottom\"),\n",
        "        ):\n",
        "            obj.dump(os.path.join(dirname, str(i), fname + \".npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_transect_from_shards(\n",
        "    transect_pth, i1=0, i2=None, dataset=\"surveyExports\", root_data_dir=ROOT_DATA_DIR\n",
        "):\n",
        "    root_shard_dir = os.path.join(root_data_dir, dataset + \"_sharded\")\n",
        "    dirname = os.path.join(root_shard_dir, transect_pth)\n",
        "    with open(os.path.join(dirname, \"shard_size.txt\"), \"r\") as f:\n",
        "        n_timestamps, shard_len = f.readline().strip().split(\",\")\n",
        "        n_timestamps = int(n_timestamps)\n",
        "        shard_len = int(shard_len)\n",
        "    if i2 is None:\n",
        "        i2 = n_timestamps\n",
        "    j1 = max(0, int(i1 / shard_len))\n",
        "    j2 = int(min(i2, n_timestamps - 1) / shard_len)\n",
        "\n",
        "    depths = np.load(os.path.join(dirname, str(j1), \"depths.npy\"), allow_pickle=True)\n",
        "\n",
        "    def load_shard(fname):\n",
        "        return np.concatenate(\n",
        "            [\n",
        "                np.load(\n",
        "                    os.path.join(dirname, str(j), fname + \".npy\"), allow_pickle=True\n",
        "                )\n",
        "                for j in range(j1, j2 + 1)\n",
        "            ]\n",
        "        )[(i1 - j1 * shard_len) : (i2 - j1 * shard_len)]\n",
        "\n",
        "    timestamps = load_shard(\"timestamps\")\n",
        "    signals = load_shard(\"Sv\")\n",
        "    d_top = load_shard(\"top\")\n",
        "    d_bot = load_shard(\"bottom\")\n",
        "\n",
        "    return timestamps, depths, signals, d_top, d_bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shard_transect(transect_pth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o = load_transect_from_shards(transect_pth)\n",
        "for io in o:\n",
        "    print(io.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o = load_transect_from_shards(transect_pth, 200, 500)\n",
        "for io in o:\n",
        "    print(io.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps, depths, signals, d_top, d_bot = load_transect_from_shards(\n",
        "    transect_pth, 100, 800\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.pcolormesh(timestamps, -depths, signals.T)\n",
        "plt.plot(timestamps, -d_bot, \"b\")\n",
        "plt.plot(timestamps, -d_top, \"c\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from echofilter.rawloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/scott/scratch/Datasets/dsforce/surveyExports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transect_data(survey, transect_name, root_dir):\n",
    "\n",
    "    dirname = os.path.join(\n",
    "        root_dir,\n",
    "        'Survey' + str(survey)\n",
    "    )\n",
    "    raw_fname = os.path.join(dirname, 'Survey{}_{}_Sv_raw.csv'.format(survey, transect_name))\n",
    "    bot_fname = os.path.join(dirname, 'Survey{}_{}_bottom.evl'.format(survey, transect_name))\n",
    "    top_fname = os.path.join(dirname, 'Survey{}_{}_turbulence.evl'.format(survey, transect_name))\n",
    "\n",
    "    timestamps, depths, signals = transect_loader(raw_fname)\n",
    "    t_bot, d_bot = evl_loader(bot_fname)\n",
    "    t_top, d_top = evl_loader(top_fname)\n",
    "\n",
    "    return timestamps, depths, signals, np.interp(timestamps, t_top, d_top), np.interp(timestamps, t_bot, d_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transect_data(survey, transect_name, root_dir):\n",
    "\n",
    "    timestamps, depths, signals, d_top, d_bot = load_transect_data(survey, transect_name, root_dir)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "    plt.plot(timestamps, -d_bot, 'b')\n",
    "    plt.plot(timestamps, -d_top, 'c')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 17\n",
    "transect_name = 'GR1_N0A_E'\n",
    "\n",
    "plot_transect_data(survey, transect_name, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_data(partition, root_dir, partitioning_version='firstpass'):\n",
    "\n",
    "    dirname = os.path.join(root_dir, 'sets', partitioning_version)\n",
    "    fname_partition = os.path.join(dirname, partition + '.txt')\n",
    "    fname_header = os.path.join(dirname, 'header' + '.txt')\n",
    "\n",
    "    with open(fname_header, 'r') as hf:\n",
    "        for row in csv.reader(hf):\n",
    "            header = [entry.strip() for entry in row]\n",
    "            break\n",
    "\n",
    "    df = pd.read_csv(fname_partition, header=None, names=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_partition_data('train', root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_file_list(partition, root_dir, include_root=True, partitioning_version='firstpass'):\n",
    "    df = get_partition_data(partition, root_dir, partitioning_version=partitioning_version)\n",
    "    fnames = df['Filename']\n",
    "    fnames = [os.path.join(f.split('_')[0], f.strip()) for f in fnames]\n",
    "    if include_root:\n",
    "        fnames = [os.path.join(root_dir, f) for f in fnames]\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_partition_file_list('train', root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<30s} {:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in get_partition_file_list('train', root_dir):\n",
    "    fname = fname.replace('Sv_raw.csv', 'bottom.evl')\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print('{:<30s} {:6.1f} {:6.1f}'.format(os.path.split(fname)[1], min(depths), max(depths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 17\n",
    "transect_name = 'GR4_S3A_E'\n",
    "\n",
    "plot_transect_data(survey, transect_name, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<30s} {:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in get_partition_file_list('validate', root_dir):\n",
    "    fname = fname.replace('Sv_raw.csv', 'bottom.evl')\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print('{:<30s} {:6.1f} {:6.1f}'.format(os.path.split(fname)[1], min(depths), max(depths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 17\n",
    "transect_name = 'GR1_S3W_F'\n",
    "\n",
    "plot_transect_data(survey, transect_name, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<30s} {:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in get_partition_file_list('test', root_dir):\n",
    "    fname = fname.replace('Sv_raw.csv', 'bottom.evl')\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print('{:<30s} {:6.1f} {:6.1f}'.format(os.path.split(fname)[1], min(depths), max(depths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<30s} {:>6s} {:>6s}'.format('Filename', 'Min D', 'Max D'))\n",
    "\n",
    "for fname in get_partition_file_list('leaveout', root_dir):\n",
    "    fname = fname.replace('Sv_raw.csv', 'bottom.evl')\n",
    "    try:\n",
    "        depths = evl_loader(fname)[1]\n",
    "    except:\n",
    "        continue\n",
    "    print('{:<30s} {:6.1f} {:6.1f}'.format(os.path.split(fname)[1], min(depths), max(depths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40, 62, 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"mytestfile.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"mydataset\", (100,), dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = 17\n",
    "transect_name = 'GR1_S3W_F'\n",
    "\n",
    "plot_transect_data(survey, transect_name, root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import echofilter.plotting\n",
        "import echofilter.raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_color = \"c\"\n",
        "bot_color = \"#00ee00\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_data_dir = \"/data/dsforce/surveyExports\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.interpolate\n",
        "import scipy.ndimage\n",
        "\n",
        "from echofilter.raw import loader, utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from echofilter.raw.manipulate import find_passive_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_DATA_DIR = loader.ROOT_DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_passive_data_v2(\n",
        "    signals,\n",
        "    n_depth_use=38,\n",
        "    threshold_inner=None,\n",
        "    threshold_init=None,\n",
        "    deviation=None,\n",
        "    sigma_depth=0,\n",
        "    sigma_time=1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Find segments of Sv recording which correspond to passive recording.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    signals : array_like\n",
        "        Two-dimensional array of Sv values, shaped `[timestamps, depths]`.\n",
        "    n_depth_use : int, optional\n",
        "        How many Sv depths to use, starting with the first depths (closest\n",
        "        to the sounder device). If `None` all depths are used. Default is `38`.\n",
        "        The median is taken across the depths, after taking the temporal\n",
        "        derivative.\n",
        "    threshold_inner : float, optional\n",
        "        Theshold to apply to the temporal derivative of the signal when\n",
        "        detected fine-tuned start/end of passive regions.\n",
        "        Default behaviour is to use a threshold automatically determined using\n",
        "        `deviation` if it is set, and otherwise use a threshold of `35.0`.\n",
        "    threshold_init : float, optional\n",
        "        Theshold to apply during the initial scan of the start/end of passive\n",
        "        regions, which seeds the fine-tuning search.\n",
        "        Default behaviour is to use a threshold automatically determined using\n",
        "        `deviation` if it is set, and otherwise use a threshold of `12.0`.\n",
        "    deviation : float, optional\n",
        "        Set `threshold_inner` to be `deviation` times the standard deviation of\n",
        "        the temporal derivative of the signal. The standard deviation is\n",
        "        robustly estimated based on the interquartile range.\n",
        "        If this is set, `threshold_inner` must not be `None`.\n",
        "        Default is `None`\n",
        "    sigma_depth : float, optional\n",
        "        Width of kernel for filtering signals across second dimension (depth).\n",
        "        Default is `0` (no filter).\n",
        "    sigma_time : float, optional\n",
        "        Width of kernel for filtering signals across second dimension (time).\n",
        "        Default is `1`. Set to `0` to not filter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    passive_start : numpy.ndarray\n",
        "        Indices of rows of `signals` at which passive segments start.\n",
        "    passive_end : numpy.ndarray\n",
        "        Indices of rows of `signals` at which passive segments end.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    Works by looking at the difference between consecutive recordings and\n",
        "    finding large deviations.\n",
        "    \"\"\"\n",
        "    # Ensure signals is numpy array\n",
        "    signals = np.asarray(signals)\n",
        "\n",
        "    if n_depth_use is None:\n",
        "        n_depth_use = signals.shape[1]\n",
        "\n",
        "    if sigma_depth > 0:\n",
        "        signals_smooth = scipy.ndimage.gaussian_filter1d(\n",
        "            signals.astype(np.float32), sigma_depth, axis=-1\n",
        "        )\n",
        "    else:\n",
        "        signals_smooth = signals\n",
        "\n",
        "    md_inner = np.median(np.diff(signals_smooth[:, :n_depth_use], axis=0), axis=1)\n",
        "\n",
        "    if sigma_time > 0:\n",
        "        signals_init = scipy.ndimage.gaussian_filter1d(\n",
        "            signals_smooth.astype(np.float32), sigma_time, axis=0\n",
        "        )\n",
        "        md_init = np.median(np.diff(signals_init[:, :n_depth_use], axis=0), axis=1)\n",
        "    else:\n",
        "        signals_init = signals\n",
        "        md_init = md_inner\n",
        "\n",
        "    if threshold_inner is not None and deviation is not None:\n",
        "        raise ValueError(\"Only one of `threshold_inner` and `deviation` should be set.\")\n",
        "    if threshold_init is None:\n",
        "        if deviation is None:\n",
        "            threshold_init = 12.0\n",
        "        else:\n",
        "            threshold_inner = (\n",
        "                (np.percentile(md_init, 75) - np.percentile(md_init, 25))\n",
        "                / 1.35\n",
        "                * deviation\n",
        "            )\n",
        "    if threshold_inner is None:\n",
        "        if deviation is None:\n",
        "            threshold_inner = 35.0\n",
        "        else:\n",
        "            threshold_inner = (\n",
        "                (np.percentile(md_inner, 75) - np.percentile(md_inner, 25))\n",
        "                / 1.35\n",
        "                * deviation\n",
        "            )\n",
        "\n",
        "    threshold_high_inner = threshold_inner\n",
        "    # threshold_low_inner = -threshold_inner\n",
        "    threshold_high_init = threshold_init\n",
        "    threshold_low_init = -threshold_init\n",
        "    indices_possible_start_init = np.nonzero(md_init < threshold_low_init)[0]\n",
        "    indices_possible_end_init = np.nonzero(md_init > threshold_high_init)[0]\n",
        "\n",
        "    if len(indices_possible_start_init) == 0 and len(indices_possible_end_init) == 0:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    # Fine tune indices without smoothing\n",
        "    indices_possible_start = []\n",
        "    indices_possible_end = []\n",
        "\n",
        "    capture_start = None\n",
        "    for i, index_p in enumerate(indices_possible_start_init):\n",
        "        if capture_start is None:\n",
        "            capture_start = index_p\n",
        "        if (\n",
        "            i + 1 >= len(indices_possible_start_init)\n",
        "            or indices_possible_start_init[i + 1] > index_p + 3\n",
        "        ):\n",
        "            # break capture\n",
        "            capture_end = index_p\n",
        "            capture = np.arange(capture_start, capture_end + 1)\n",
        "            indices_possible_start.append(capture[np.argmin(md_init[capture])])\n",
        "            capture_start = None\n",
        "\n",
        "    capture_start = None\n",
        "    for i, index_p in enumerate(indices_possible_end_init):\n",
        "        if capture_start is None:\n",
        "            capture_start = index_p\n",
        "        if (\n",
        "            i + 1 >= len(indices_possible_end_init)\n",
        "            or indices_possible_end_init[i + 1] > index_p + 3\n",
        "        ):\n",
        "            # break capture\n",
        "            capture_end = index_p\n",
        "            capture = np.arange(capture_start, capture_end + 1)\n",
        "            indices_possible_end.append(capture[np.argmax(md_init[capture])])\n",
        "            capture_start = None\n",
        "\n",
        "    indices_possible_start = np.array(indices_possible_start)\n",
        "    indices_possible_end = np.array(indices_possible_end)\n",
        "\n",
        "    current_index = 0\n",
        "    indices_passive_start = []\n",
        "    indices_passive_end = []\n",
        "\n",
        "    if len(indices_possible_start) > 0:\n",
        "        indices_possible_start += 1\n",
        "\n",
        "    if len(indices_possible_end) > 0:\n",
        "        indices_possible_end += 1\n",
        "\n",
        "    if len(indices_possible_end) > 0 and (\n",
        "        len(indices_possible_start) == 0\n",
        "        or indices_possible_end[0] < indices_possible_start[0]\n",
        "    ):\n",
        "        indices_passive_start.append(0)\n",
        "        current_index = indices_possible_end[0]\n",
        "        indices_passive_end.append(current_index)\n",
        "        indices_possible_start = indices_possible_start[\n",
        "            indices_possible_start > current_index\n",
        "        ]\n",
        "        indices_possible_end = indices_possible_end[\n",
        "            indices_possible_end > current_index\n",
        "        ]\n",
        "\n",
        "    while len(indices_possible_start) > 0:\n",
        "        current_index = indices_possible_start[0]\n",
        "        indices_passive_start.append(current_index)\n",
        "        baseline_index = max(0, current_index - 2)\n",
        "        baseline = signals[baseline_index, :n_depth_use]\n",
        "\n",
        "        # Find first column which returns to the baseline value seen before passive region\n",
        "        offsets = np.nonzero(\n",
        "            np.median(baseline - signals[current_index:, :n_depth_use], axis=1)\n",
        "            < threshold_high_inner\n",
        "        )[0]\n",
        "        if len(offsets) == 0:\n",
        "            current_index = signals.shape[0]\n",
        "        else:\n",
        "            current_index += offsets[0]\n",
        "        indices_passive_end.append(current_index)\n",
        "\n",
        "        # Remove preceding indices from the list of candidates\n",
        "        indices_possible_start = indices_possible_start[\n",
        "            indices_possible_start > current_index\n",
        "        ]\n",
        "        indices_possible_end = indices_possible_end[\n",
        "            indices_possible_end > current_index\n",
        "        ]\n",
        "\n",
        "        # Check the start was sufficiently inclusive\n",
        "        if current_index < signals.shape[0]:\n",
        "            baseline_index = min(signals.shape[0] - 1, current_index + 1)\n",
        "            baseline = signals[baseline_index, :n_depth_use]\n",
        "            nonpassives = np.nonzero(\n",
        "                np.median(baseline - signals[:current_index, :n_depth_use], axis=1)\n",
        "                < threshold_high_inner\n",
        "            )[0]\n",
        "            if len(nonpassives) == 0:\n",
        "                indices_passive_start[-1] = 0\n",
        "            else:\n",
        "                indices_passive_start[-1] = min(\n",
        "                    indices_passive_start[-1],\n",
        "                    nonpassives[-1] + 1,\n",
        "                )\n",
        "\n",
        "        # Combine with preceding passive segments if they overlap\n",
        "        while (\n",
        "            len(indices_passive_start) > 1\n",
        "            and indices_passive_start[-1] <= indices_passive_end[-2]\n",
        "        ):\n",
        "            indices_passive_start = indices_passive_start[:-1]\n",
        "            indices_passive_end = indices_passive_end[:-2] + indices_passive_end[-1:]\n",
        "\n",
        "    return np.array(indices_passive_start), np.array(indices_passive_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_paths = []\n",
        "for dataset in [\"MinasPassage\", \"GrandPassage\", \"mobile\"]:\n",
        "    for partition in [\"train\", \"validate\", \"test\"]:\n",
        "        sample_paths += [\n",
        "            os.path.join(dataset, pth)\n",
        "            for pth in loader.get_partition_list(partition, dataset=dataset)\n",
        "        ]\n",
        "sample_paths = sorted(sample_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Begin running on {} paths\\n\".format(len(sample_paths)))\n",
        "\n",
        "for i_sample, sample_path in enumerate(sample_paths):\n",
        "\n",
        "    print(\n",
        "        \"{:4d}/{:4d} {}\".format(\n",
        "            i_sample + 1,\n",
        "            len(sample_paths),\n",
        "            datetime.datetime.now().strftime(\"%A, %B %d, %Y at %H:%M:%S\"),\n",
        "        )\n",
        "    )\n",
        "    print(sample_path)\n",
        "\n",
        "    fname_raw = os.path.join(root_data_dir, sample_path + \"_Sv_raw.csv\")\n",
        "    ts_raw, depths_raw, signals_raw = echofilter.raw.loader.transect_loader(\n",
        "        fname_raw, warn_row_overflow=0\n",
        "    )\n",
        "    is_upward_facing = depths_raw[-1] < depths_raw[0]\n",
        "\n",
        "    nt = len(ts_raw)\n",
        "    print(\"length: {}\".format(nt))\n",
        "    its_raw = np.arange(len(ts_raw))\n",
        "\n",
        "    if \"december2017\" in sample_path:\n",
        "        psx = np.array([])\n",
        "        pex = np.array([])\n",
        "    elif \"march2018\" in sample_path:\n",
        "        psx = np.arange(0, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"september2018\" in sample_path:\n",
        "        psx = np.arange(300, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"GrandPassage\" in sample_path:\n",
        "        psx = np.array([0, 3120, 6540, 9960, 13380])\n",
        "        psx = psx[psx < nt]\n",
        "        pex = np.r_[120, psx[1:] + 420]\n",
        "        pex = np.minimum(pex, nt)\n",
        "    else:\n",
        "        psx = None\n",
        "        pex = None\n",
        "\n",
        "    def tidy_up_line(t, d):\n",
        "        if d is None:\n",
        "            return np.nan * np.ones_like(ts_raw)\n",
        "        is_usable = np.isfinite(d)\n",
        "        if np.sum(is_usable) > 0:\n",
        "            t = t[is_usable]\n",
        "            d = d[is_usable]\n",
        "        return np.interp(ts_raw, t, d)\n",
        "\n",
        "    ps1, pe1 = find_passive_data(signals_raw)\n",
        "    ps2, pe2 = find_passive_data_v2(signals_raw)\n",
        "\n",
        "    fname_surface = os.path.join(root_data_dir, sample_path + \"_surface.evl\")\n",
        "\n",
        "    if os.path.isfile(fname_surface):\n",
        "        t_surface, d_surface = loader.evl_loader(fname_surface)\n",
        "    elif is_upward_facing:\n",
        "        print(\n",
        "            \"ERROR: Expected {} to exist when transect is upfacing.\".format(\n",
        "                fname_surface\n",
        "            )\n",
        "        )\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "    else:\n",
        "        # Default surface depth of 0m for downward facing data\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "\n",
        "    # Find location of passive data.\n",
        "    # Try to determine passive data as whenever the surface line is undefined.\n",
        "    d_surface[np.isclose(d_surface, -10000.99)] = np.nan\n",
        "    is_passive = np.isnan(d_surface)\n",
        "    ps3, pe3 = echofilter.utils.get_indicator_onoffsets(is_passive > 0.5)\n",
        "    ps3 = np.asarray(ps3)\n",
        "    pe3 = np.asarray(pe3) + 1\n",
        "    pl3 = pe3 - ps3\n",
        "    li = pl3 >= 3\n",
        "    ps3 = ps3[li]\n",
        "    pe3 = pe3[li]\n",
        "    if np.sum(~li) > 0:\n",
        "        print(\"popped {} from v3, with lengths {}\".format(np.sum(~li), pl3[~li]))\n",
        "\n",
        "    print(\"starts:\")\n",
        "    print(\"xp:\", psx)\n",
        "    print(\"v1:\", ps1)\n",
        "    print(\"v2:\", ps2)\n",
        "    print(\"v3:\", ps3)\n",
        "    print(\"ends:\")\n",
        "    print(\"xp:\", pex)\n",
        "    print(\"v1:\", pe1)\n",
        "    print(\"v2:\", pe2)\n",
        "    print(\"v3:\", pe3)\n",
        "    print(\"durations:\")\n",
        "    if pex is not None:\n",
        "        print(\"xp:\", pex - psx)\n",
        "    print(\"v1:\", pe1 - ps1)\n",
        "    print(\"v2:\", pe2 - ps2)\n",
        "    if ps3 is not None:\n",
        "        print(\"v3:\", pe3 - ps3)\n",
        "    print(\"\")\n",
        "\n",
        "    if (\n",
        "        len(ps1) != len(ps2)\n",
        "        or len(pe1) != len(pe2)\n",
        "        or not np.allclose(ps1, ps2)\n",
        "        or not np.allclose(pe1, pe2)\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v1/v2\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and (\n",
        "            len(ps3) != len(ps2)\n",
        "            or len(pe3) != len(pe2)\n",
        "            or not np.allclose(ps3, ps2)\n",
        "            or not np.allclose(pe3, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v2/v3\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps1)\n",
        "            or len(pex) != len(pe1)\n",
        "            or not np.allclose(psx, ps1)\n",
        "            or not np.allclose(pex, pe1)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v1 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps2)\n",
        "            or len(pex) != len(pe2)\n",
        "            or not np.allclose(psx, ps2)\n",
        "            or not np.allclose(pex, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v2 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps3)\n",
        "            or len(pex) != len(pe3)\n",
        "            or not np.allclose(psx, ps3)\n",
        "            or not np.allclose(pex, pe3)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v3 DISAGREES WITH EXPECTED\")\n",
        "\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_paths = []\n",
        "dataset = \"mobile\"\n",
        "sample_paths = [\n",
        "    os.path.join(dataset, pth)\n",
        "    for pth in loader.get_partition_list(\"leaveout\", dataset=dataset)\n",
        "]\n",
        "sample_paths = sorted(sample_paths)\n",
        "\n",
        "\n",
        "print(\"Begin running on {} paths\\n\".format(len(sample_paths)))\n",
        "\n",
        "for i_sample, sample_path in enumerate(sample_paths):\n",
        "\n",
        "    print(\n",
        "        \"{:4d}/{:4d} {}\".format(\n",
        "            i_sample + 1,\n",
        "            len(sample_paths),\n",
        "            datetime.datetime.now().strftime(\"%A, %B %d, %Y at %H:%M:%S\"),\n",
        "        )\n",
        "    )\n",
        "    print(sample_path)\n",
        "\n",
        "    fname_raw = os.path.join(root_data_dir, sample_path + \"_Sv_raw.csv\")\n",
        "    ts_raw, depths_raw, signals_raw = echofilter.raw.loader.transect_loader(\n",
        "        fname_raw, warn_row_overflow=0\n",
        "    )\n",
        "    is_upward_facing = depths_raw[-1] < depths_raw[0]\n",
        "\n",
        "    nt = len(ts_raw)\n",
        "    print(\"length: {}\".format(nt))\n",
        "    its_raw = np.arange(len(ts_raw))\n",
        "\n",
        "    if \"december2017\" in sample_path:\n",
        "        psx = np.array([])\n",
        "        pex = np.array([])\n",
        "    elif \"march2018\" in sample_path:\n",
        "        psx = np.arange(0, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"september2018\" in sample_path:\n",
        "        psx = np.arange(300, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"GrandPassage\" in sample_path:\n",
        "        psx = np.array([0, 3120, 6540, 9960, 13380])\n",
        "        psx = psx[psx < nt]\n",
        "        pex = np.r_[120, psx[1:] + 420]\n",
        "        pex = np.minimum(pex, nt)\n",
        "    else:\n",
        "        psx = None\n",
        "        pex = None\n",
        "\n",
        "    ps1, pe1 = find_passive_data(signals_raw)\n",
        "    ps2, pe2 = find_passive_data_v2(signals_raw)\n",
        "\n",
        "    fname_surface = os.path.join(root_data_dir, sample_path + \"_surface.evl\")\n",
        "\n",
        "    if os.path.isfile(fname_surface):\n",
        "        t_surface, d_surface = loader.evl_loader(fname_surface)\n",
        "    elif is_upward_facing:\n",
        "        print(\n",
        "            \"ERROR: Expected {} to exist when transect is upfacing.\".format(\n",
        "                fname_surface\n",
        "            )\n",
        "        )\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "    else:\n",
        "        # Default surface depth of 0m for downward facing data\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "\n",
        "    # Find location of passive data.\n",
        "    # Try to determine passive data as whenever the surface line is undefined.\n",
        "    d_surface[np.isclose(d_surface, -10000.99)] = np.nan\n",
        "    is_passive = np.isnan(d_surface)\n",
        "    ps3, pe3 = echofilter.utils.get_indicator_onoffsets(is_passive > 0.5)\n",
        "    ps3 = np.asarray(ps3)\n",
        "    pe3 = np.asarray(pe3) + 1\n",
        "    pl3 = pe3 - ps3\n",
        "    li = pl3 >= 3\n",
        "    ps3 = ps3[li]\n",
        "    pe3 = pe3[li]\n",
        "    if np.sum(~li) > 0:\n",
        "        print(\"popped {} from v3, with lengths {}\".format(np.sum(~li), pl3[~li]))\n",
        "\n",
        "    print(\"starts:\")\n",
        "    print(\"xp:\", psx)\n",
        "    print(\"v1:\", ps1)\n",
        "    print(\"v2:\", ps2)\n",
        "    print(\"v3:\", ps3)\n",
        "    print(\"ends:\")\n",
        "    print(\"xp:\", pex)\n",
        "    print(\"v1:\", pe1)\n",
        "    print(\"v2:\", pe2)\n",
        "    print(\"v3:\", pe3)\n",
        "    print(\"durations:\")\n",
        "    if pex is not None:\n",
        "        print(\"xp:\", pex - psx)\n",
        "    print(\"v1:\", pe1 - ps1)\n",
        "    print(\"v2:\", pe2 - ps2)\n",
        "    if ps3 is not None:\n",
        "        print(\"v3:\", pe3 - ps3)\n",
        "    print(\"\")\n",
        "\n",
        "    if (\n",
        "        len(ps1) != len(ps2)\n",
        "        or len(pe1) != len(pe2)\n",
        "        or not np.allclose(ps1, ps2)\n",
        "        or not np.allclose(pe1, pe2)\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v1/v2\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and (\n",
        "            len(ps3) != len(ps2)\n",
        "            or len(pe3) != len(pe2)\n",
        "            or not np.allclose(ps3, ps2)\n",
        "            or not np.allclose(pe3, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v2/v3\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps1)\n",
        "            or len(pex) != len(pe1)\n",
        "            or not np.allclose(psx, ps1)\n",
        "            or not np.allclose(pex, pe1)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v1 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps2)\n",
        "            or len(pex) != len(pe2)\n",
        "            or not np.allclose(psx, ps2)\n",
        "            or not np.allclose(pex, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v2 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps3)\n",
        "            or len(pex) != len(pe3)\n",
        "            or not np.allclose(psx, ps3)\n",
        "            or not np.allclose(pex, pe3)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v3 DISAGREES WITH EXPECTED\")\n",
        "\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bad_sample_paths = [\n",
        "    \"MinasPassage/september2018/september2018_D20181021-T165220_D20181021-T222221\",\n",
        "    \"MinasPassage/september2018/september2018_D20181022-T105220_D20181022-T162217\",\n",
        "    \"MinasPassage/september2018/september2018_D20181022-T172213_D20181022-T232217\",\n",
        "    \"MinasPassage/september2018/september2018_D20181026-T082220_D20181026-T135213\",\n",
        "    \"MinasPassage/september2018/september2018_D20181026-T142217_D20181026-T195218\",\n",
        "]\n",
        "# bad_sample_paths = [\n",
        "# \"MinasPassage/september2018/september2018_D20180928-T202217_D20180929-T015217\",\n",
        "# \"MinasPassage/september2018/september2018_D20181008-T235218_D20181009-T052220\",\n",
        "# \"MinasPassage/september2018/september2018_D20181021-T045220_D20181021-T102218\",\n",
        "# ]\n",
        "# bad_sample_paths = [\n",
        "#    \"GrandPassage/phase2/GrandPassage_WBAT_2B_20200130_UTC020017_floodhigh\",\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Begin running on {} paths\\n\".format(len(bad_sample_paths)))\n",
        "\n",
        "for i_sample, sample_path in enumerate(bad_sample_paths):\n",
        "\n",
        "    print(\n",
        "        \"{:4d}/{:4d} {}\".format(\n",
        "            i_sample + 1,\n",
        "            len(bad_sample_paths),\n",
        "            datetime.datetime.now().strftime(\"%A, %B %d, %Y at %H:%M:%S\"),\n",
        "        )\n",
        "    )\n",
        "    print(sample_path)\n",
        "\n",
        "    fname_raw = os.path.join(root_data_dir, sample_path + \"_Sv_raw.csv\")\n",
        "    ts_raw, depths_raw, signals_raw = echofilter.raw.loader.transect_loader(\n",
        "        fname_raw, warn_row_overflow=0\n",
        "    )\n",
        "    is_upward_facing = depths_raw[-1] < depths_raw[0]\n",
        "\n",
        "    nt = len(ts_raw)\n",
        "    print(\"length: {}\".format(nt))\n",
        "    its_raw = np.arange(len(ts_raw))\n",
        "\n",
        "    if \"december2017\" in sample_path:\n",
        "        psx = np.array([])\n",
        "        pex = np.array([])\n",
        "    elif \"march2018\" in sample_path:\n",
        "        psx = np.arange(0, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"september2018\" in sample_path:\n",
        "        psx = np.arange(300, nt, 360)\n",
        "        pex = psx + 60\n",
        "    elif \"GrandPassage\" in sample_path:\n",
        "        psx = np.array([0, 3120, 6540, 9960, 13380])\n",
        "        psx = psx[psx < nt]\n",
        "        pex = np.r_[120, psx[1:] + 420]\n",
        "        pex = np.minimum(pex, nt)\n",
        "    else:\n",
        "        psx = None\n",
        "        pex = None\n",
        "\n",
        "    ps1, pe1 = find_passive_data(signals_raw)\n",
        "    ps2, pe2 = find_passive_data_v2(signals_raw)\n",
        "\n",
        "    fname_surface = os.path.join(root_data_dir, sample_path + \"_surface.evl\")\n",
        "\n",
        "    if os.path.isfile(fname_surface):\n",
        "        t_surface, d_surface = loader.evl_loader(fname_surface)\n",
        "    elif is_upward_facing:\n",
        "        print(\n",
        "            \"ERROR: Expected {} to exist when transect is upfacing.\".format(\n",
        "                fname_surface\n",
        "            )\n",
        "        )\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "    else:\n",
        "        # Default surface depth of 0m for downward facing data\n",
        "        t_surface = ts_raw\n",
        "        d_surface = np.zeros_like(ts_raw)\n",
        "\n",
        "    # Find location of passive data.\n",
        "    # Try to determine passive data as whenever the surface line is undefined.\n",
        "    d_surface[np.isclose(d_surface, -10000.99)] = np.nan\n",
        "    is_passive = np.isnan(d_surface)\n",
        "    ps3, pe3 = echofilter.utils.get_indicator_onoffsets(is_passive > 0.5)\n",
        "    ps3 = np.asarray(ps3)\n",
        "    pe3 = np.asarray(pe3) + 1\n",
        "    pl3 = pe3 - ps3\n",
        "    li = pl3 >= 3\n",
        "    ps3 = ps3[li]\n",
        "    pe3 = pe3[li]\n",
        "    if np.sum(~li) > 0:\n",
        "        print(\"popped {} from v3, with lengths {}\".format(np.sum(~li), pl3[~li]))\n",
        "\n",
        "    print(\"starts:\")\n",
        "    print(\"xp:\", psx)\n",
        "    print(\"v1:\", ps1)\n",
        "    print(\"v2:\", ps2)\n",
        "    print(\"v3:\", ps3)\n",
        "    print(\"ends:\")\n",
        "    print(\"xp:\", pex)\n",
        "    print(\"v1:\", pe1)\n",
        "    print(\"v2:\", pe2)\n",
        "    print(\"v3:\", pe3)\n",
        "    print(\"durations:\")\n",
        "    if pex is not None:\n",
        "        print(\"xp:\", pex - psx)\n",
        "    print(\"v1:\", pe1 - ps1)\n",
        "    print(\"v2:\", pe2 - ps2)\n",
        "    if ps3 is not None:\n",
        "        print(\"v3:\", pe3 - ps3)\n",
        "    print(\"\")\n",
        "\n",
        "    if (\n",
        "        len(ps1) != len(ps2)\n",
        "        or len(pe1) != len(pe2)\n",
        "        or not np.allclose(ps1, ps2)\n",
        "        or not np.allclose(pe1, pe2)\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v1/v2\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and (\n",
        "            len(ps3) != len(ps2)\n",
        "            or len(pe3) != len(pe2)\n",
        "            or not np.allclose(ps3, ps2)\n",
        "            or not np.allclose(pe3, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: DIFFERENT PASSIVE PREDICTIONS v2/v3\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps1)\n",
        "            or len(pex) != len(pe1)\n",
        "            or not np.allclose(psx, ps1)\n",
        "            or not np.allclose(pex, pe1)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v1 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps2)\n",
        "            or len(pex) != len(pe2)\n",
        "            or not np.allclose(psx, ps2)\n",
        "            or not np.allclose(pex, pe2)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v2 DISAGREES WITH EXPECTED\")\n",
        "    if (\n",
        "        ps3 is not None\n",
        "        and pe3 is not None\n",
        "        and psx is not None\n",
        "        and pex is not None\n",
        "        and (\n",
        "            len(psx) != len(ps3)\n",
        "            or len(pex) != len(pe3)\n",
        "            or not np.allclose(psx, ps3)\n",
        "            or not np.allclose(pex, pe3)\n",
        "        )\n",
        "    ):\n",
        "        print(\"Warning: PASSIVE v3 DISAGREES WITH EXPECTED\")\n",
        "\n",
        "    best_ps = ps1\n",
        "    best_pe = pe1\n",
        "\n",
        "    for i in range(min(len(best_ps), len(psx))):\n",
        "        if best_ps[i] == psx[i] and best_pe[i] == pex[i]:\n",
        "            continue\n",
        "\n",
        "        for ps, pe, tit in (\n",
        "            (psx[i], pex[i], \"expected\"),\n",
        "            (best_ps[i], best_pe[i], \"v1\"),\n",
        "        ):\n",
        "            plt.figure(figsize=(12, 9))\n",
        "            i0 = max(0, ps - 1)\n",
        "            i1 = pe + 2\n",
        "            if i1 >= len(its_raw):\n",
        "                i1 = None\n",
        "            plt.pcolormesh(its_raw[i0:i1], depths_raw[:50], signals_raw[i0:i1, :50].T)\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.title(\"passive #{}, {}\".format(i, tit))\n",
        "            plt.show()\n",
        "\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.pcolormesh(its_raw, depths_raw, signals_raw.T)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(sample_path)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = \"\"\"\n",
        "length: 10259\n",
        "starts:\n",
        "xp: [   0 3120 6540 9960]\n",
        "v1: [   0 3120 6539 9959]\n",
        "v2: [   0 3120 6539 9959]\n",
        "v3: [   0 3120 6540 9960]\n",
        "ends:\n",
        "xp: [  120  3540  6960 10259]\n",
        "v1: [  120  3540  6959 10259]\n",
        "v2: [  120  3540  6701 10259]\n",
        "v3: [  120  3540  6960 10260]\n",
        "durations:\n",
        "xp: [120 420 420 299]\n",
        "v1: [120 420 420 300]\n",
        "v2: [120 420 162 300]\n",
        "v3: [120 420 420 300]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i0 = 10200\n",
        "i1 = 10259\n",
        "i0 -= 1\n",
        "i1 += 2\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.pcolormesh(its_raw[i0:i1], depths_raw[:50], signals_raw[i0:i1, :50].T)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"{}-{}\".format(i0, i1 - 1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_path = (\n",
        "    \"MinasPassage/december2017/december2017_D20180222-T145219_D20180222-T142214\"\n",
        ")\n",
        "\n",
        "fname_raw = os.path.join(root_data_dir, sample_path + \"_Sv_raw.csv\")\n",
        "ts_raw, depths_raw, signals_raw = echofilter.raw.loader.transect_loader(\n",
        "    fname_raw, warn_row_overflow=0\n",
        ")\n",
        "is_upward_facing = depths_raw[-1] < depths_raw[0]\n",
        "\n",
        "nt = len(ts_raw)\n",
        "print(\"length: {}\".format(nt))\n",
        "its_raw = np.arange(len(ts_raw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.pcolormesh(its_raw, depths_raw, signals_raw.T)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(sample_path)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i0 = 250\n",
        "i1 = 350\n",
        "i0 -= 1\n",
        "i1 += 2\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.pcolormesh(its_raw[i0:i1], depths_raw[:50], signals_raw[i0:i1, :50].T)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"{}-{}\".format(i0, i1 - 1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bad_sample_paths = [\n",
        "    \"mobile/Survey01/Survey01_GR1_S1A_E\",\n",
        "    \"mobile/Survey03/Survey03_GR2_N5W_survey3\",\n",
        "    \"mobile/Survey03/Survey03_GR4_N0A_survey3\",\n",
        "    \"mobile/Survey04/Survey04_GR1_N3A\",\n",
        "    \"mobile/Survey04/Survey04_GR2_N5A\",\n",
        "    \"mobile/Survey05/Survey05_GR1_N1A_survey5\",\n",
        "    \"mobile/Survey07/Survey07_GR2_N1W_survey7\",\n",
        "    \"mobile/Survey10/Survey10_GR1_N0A_E\",\n",
        "    \"mobile/Survey12/Survey12_GR4_N5A_E\",\n",
        "    \"mobile/Survey01/Survey01_GR1_S2A_E\",\n",
        "    \"mobile/Survey01/Survey01_GR1_S2W_E\",\n",
        "    \"mobile/Survey11/Survey11_GR1_S2A_E\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Begin running on {} paths\\n\".format(len(bad_sample_paths)))\n",
        "\n",
        "for i_sample, sample_path in enumerate(bad_sample_paths):\n",
        "\n",
        "    print(\n",
        "        \"{:4d}/{:4d} {}\".format(\n",
        "            i_sample + 1,\n",
        "            len(bad_sample_paths),\n",
        "            datetime.datetime.now().strftime(\"%A, %B %d, %Y at %H:%M:%S\"),\n",
        "        )\n",
        "    )\n",
        "    print(sample_path)\n",
        "\n",
        "    fname_raw = os.path.join(root_data_dir, sample_path + \"_Sv_raw.csv\")\n",
        "    ts_raw, depths_raw, signals_raw = echofilter.raw.loader.transect_loader(\n",
        "        fname_raw, warn_row_overflow=0\n",
        "    )\n",
        "    is_upward_facing = depths_raw[-1] < depths_raw[0]\n",
        "\n",
        "    nt = len(ts_raw)\n",
        "    print(\"length: {}\".format(nt))\n",
        "    its_raw = np.arange(len(ts_raw))\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.pcolormesh(its_raw, depths_raw, signals_raw.T)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(sample_path)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

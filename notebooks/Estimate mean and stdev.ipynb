{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import echofilter.raw\n",
    "import echofilter.raw.shardloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = echofilter.raw.loader.ROOT_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 'train'\n",
    "partitioning_version = 'firstpass'\n",
    "dataset = 'mobile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pths = echofilter.raw.loader.get_partition_list(\n",
    "    partition,\n",
    "    dataset=dataset,\n",
    "    partitioning_version=partitioning_version,\n",
    "    root_data_dir=root_data_dir,\n",
    "    full_path=True,\n",
    "    sharded=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pth = transect_pths[0]\n",
    "with open(os.path.join(transect_pth, 'n_segment.txt'), 'r') as f:\n",
    "    n_segment = int(f.readline().strip())\n",
    "\n",
    "i_seg = 0\n",
    "transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
    "    os.path.join(transect_pth, str(i_seg))\n",
    ")\n",
    "transect['Sv'] = transect['Sv'][1:, transect['depths'] <= max_depth]\n",
    "transect['Sv'] = transect['Sv'].astype(np.float32)\n",
    "print('mean', np.mean(transect['Sv']))\n",
    "print('median', np.median(transect['Sv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile([5, 3, 5, 4, np.nan], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect['Sv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(transect['Sv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [0, .1, 1, 5, 7, 10, 25, 50, 75, 90, 93, 95, 99, 99.9, 100]\n",
    "ps = np.percentile(transect['Sv'], qs)\n",
    "for q, p in zip(qs, ps):\n",
    "    print('{:5.1f} {:7.2f}'.format(q, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.percentile(transect['Sv'], [10, 90])) / 2.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.percentile(transect['Sv'], [7, 93])) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.percentile(transect['Sv'], [25, 75])) / 1.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(transect['Sv'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = np.median(np.abs(transect['Sv'] - np.median(transect['Sv'])))\n",
    "print(mad)\n",
    "print(mad * 1.4826)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(transect['Sv'], [60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.diff(np.percentile(transect['Sv'], [60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(transect['Sv'], [40, 35, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    transect_pth = transect_pths[i]\n",
    "    with open(os.path.join(transect_pth, 'n_segment.txt'), 'r') as f:\n",
    "        n_segment = int(f.readline().strip())\n",
    "\n",
    "    i_seg = 0\n",
    "    transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
    "        os.path.join(transect_pth, str(i_seg))\n",
    "    )\n",
    "    transect['Sv'] = transect['Sv'][1:, transect['depths'] <= max_depth]\n",
    "    transect['Sv'] = transect['Sv'].astype(np.float32)\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.distplot(transect['Sv'])\n",
    "    plt.show()\n",
    "\n",
    "    print('{:6s} {:7.2f}'.format('mean', np.mean(transect['Sv'])))\n",
    "    print('{:6s} {:7.2f}'.format('median', np.median(transect['Sv'])))\n",
    "    print('{:6s} {:7.2f}'.format('stdev', np.std(transect['Sv'])))\n",
    "    print('{:6s} {:7.2f}'.format('mad', np.median(np.abs(transect['Sv'][1:] - np.median(transect['Sv'])))))\n",
    "    print('{:6s} {:7.2f}'.format('iqr', np.diff(np.percentile(transect['Sv'], [25, 75]))[0]))\n",
    "    print('{:6s} {:7.2f}'.format('idr', np.diff(np.percentile(transect['Sv'], [10, 90]))[0]))\n",
    "    print('{:6s} {:7.2f}'.format('i7r', np.diff(np.percentile(transect['Sv'], [7, 93]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stdevs = []\n",
    "medians = []\n",
    "mads = []\n",
    "percentiles = []\n",
    "std25 = []\n",
    "\n",
    "qs = [0, .1, 1, 5, 7, 10, 15, 20, 25, 30, 35, 40, 50, 75, 90, 93, 95, 99, 99.9, 100]\n",
    "\n",
    "for transect_pth in tqdm(transect_pths):\n",
    "\n",
    "    try:\n",
    "        # Check how many segments the transect was divided into\n",
    "        with open(os.path.join(transect_pth, 'n_segment.txt'), 'r') as f:\n",
    "            n_segment = int(f.readline().strip())\n",
    "\n",
    "        for i_seg in range(n_segment):\n",
    "            transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
    "                os.path.join(transect_pth, str(i_seg))\n",
    "            )\n",
    "            transect['Sv'] = transect['Sv'][1:, transect['depths'] <= max_depth]\n",
    "            if len(transect['Sv']) < 2:\n",
    "                continue\n",
    "            transect['Sv'] = transect['Sv'].astype(np.float32)\n",
    "            means.append(np.nanmean(transect['Sv']))\n",
    "            stdevs.append(np.nanstd(transect['Sv']))\n",
    "            median = np.nanmedian(transect['Sv'])\n",
    "            medians.append(median)\n",
    "            mads.append(np.nanmedian(np.abs(transect['Sv'] - median)))\n",
    "            percentiles.append(np.nanpercentile(transect['Sv'], qs))\n",
    "            pc25 = np.nanpercentile(transect['Sv'], 25)\n",
    "            std25.append(np.sqrt(np.nanmean(np.power(transect['Sv'] - pc25, 2))))\n",
    "\n",
    "    except Exception as ex:\n",
    "        print('Error loading shard from {}'.format(transect_pth))\n",
    "        print(ex)\n",
    "\n",
    "MEAN = np.nanmean(means)\n",
    "print('mean = {}'.format(MEAN))\n",
    "print('mean of medians = {}'.format(np.nanmean(medians)))\n",
    "\n",
    "qs = np.array(qs)\n",
    "percentiles = np.array(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = []\n",
    "\n",
    "for transect_pth in tqdm(transect_pths):\n",
    "\n",
    "    try:\n",
    "        # Check how many segments the transect was divided into\n",
    "        with open(os.path.join(transect_pth, 'n_segment.txt'), 'r') as f:\n",
    "            n_segment = int(f.readline().strip())\n",
    "\n",
    "        for i_seg in range(n_segment):\n",
    "            transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
    "                os.path.join(transect_pth, str(i_seg))\n",
    "            )\n",
    "            transect['Sv'] = transect['Sv'][1:, transect['depths'] <= max_depth]\n",
    "            if len(transect['Sv']) < 2:\n",
    "                continue\n",
    "            transect['Sv'] = transect['Sv'].astype(np.float32)\n",
    "            variances.append(np.nanmean(np.power(transect['Sv'] - MEAN, 2)))\n",
    "    except Exception as ex:\n",
    "        print('Error loading shard from {}'.format(transect_pth))\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "VARIANCE = np.mean(variances)\n",
    "print('variance = {}'.format(VARIANCE))\n",
    "print('stdev = {}'.format(np.sqrt(VARIANCE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqrs = percentiles[:, np.nonzero(qs == 75)[0][0]] - percentiles[:, np.nonzero(qs == 25)[0][0]]\n",
    "IQR = np.mean(iqrs)\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idrs = percentiles[:, np.nonzero(qs == 90)[0][0]] - percentiles[:, np.nonzero(qs == 10)[0][0]]\n",
    "IDR = np.mean(idrs)\n",
    "print(IDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i7rs = percentiles[:, np.nonzero(qs == 93)[0][0]] - percentiles[:, np.nonzero(qs == 7)[0][0]]\n",
    "I7R = np.mean(i7rs)\n",
    "print(I7R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(VARIANCE))\n",
    "print(np.mean(stdevs))\n",
    "\n",
    "print(np.mean(mads) * 1.4826)\n",
    "print(IQR / 1.35)\n",
    "print(IDR / 2.56)\n",
    "print(I7R / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    '{:6s} {:6s}  {:6s}  {:6s}  {:6s}  {:5s}  {:5s}  {:5s}'\n",
    "    .format('name', 'SEM', 'mean', 'min', 'max', 'pcerr', 'pcstd', 'pcran')\n",
    ")\n",
    "for name, estimator in [\n",
    "    ('mean', means),\n",
    "    ('median', medians),\n",
    "    ('stdev', stdevs),\n",
    "    ('MAD', mads),\n",
    "    ('IQR', iqrs),\n",
    "    ('IDR', idrs),\n",
    "    ('I7R', i7rs),\n",
    "    ('std25', std25),\n",
    "]:\n",
    "    print(\n",
    "        '{:6s} {:6.4f}  {:6.1f}  {:6.1f}  {:6.1f}  {:5.3f}  {:5.2f}  {:5.1f}'\n",
    "        .format(\n",
    "            name,\n",
    "            scipy.stats.sem(estimator),\n",
    "            np.mean(estimator),\n",
    "            np.min(estimator),\n",
    "            np.max(estimator),\n",
    "            scipy.stats.sem(estimator) / np.abs(np.mean(estimator)) * 100,\n",
    "            np.std(estimator) / np.abs(np.mean(estimator)) * 100,\n",
    "            (np.max(estimator) - np.min(estimator)) / np.abs(np.mean(estimator)) * 100,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    '{:6s}  {:6s}  {:6s}  {:6s}  {:6s}  {:5s}  {:5s}  {:5s}'\n",
    "    .format('percentile', 'SEM', 'mean', 'min', 'max', 'pcerr', 'pcstd', 'pcran')\n",
    ")\n",
    "for iq, q in enumerate(qs):\n",
    "    estimator = percentiles[:, iq]\n",
    "    print(\n",
    "        '{:10.1f}  {:6.4f}  {:6.1f}  {:6.1f}  {:6.1f}  {:5.3f}  {:5.2f}  {:5.1f}'\n",
    "        .format(\n",
    "            q,\n",
    "            scipy.stats.sem(estimator),\n",
    "            np.mean(estimator),\n",
    "            np.min(estimator),\n",
    "            np.max(estimator),\n",
    "            scipy.stats.sem(estimator) / np.abs(np.mean(estimator)) * 100,\n",
    "            np.std(estimator) / np.abs(np.mean(estimator)) * 100,\n",
    "            (np.max(estimator) - np.min(estimator)) / np.abs(np.mean(estimator)) * 100,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(means)\n",
    "plt.title('mean estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(medians)\n",
    "plt.title('median estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(stdevs)\n",
    "plt.title('standard deviation estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(mads)\n",
    "plt.title('MAD estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(iqrs)\n",
    "plt.title('IQR estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(idrs)\n",
    "plt.title('IDR estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.distplot(i7rs)\n",
    "plt.title('7-93 estimates')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

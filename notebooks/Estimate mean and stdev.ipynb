{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.autonotebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import echofilter.raw\n",
        "import echofilter.raw.shardloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_data_dir = echofilter.raw.loader.ROOT_DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "partition = \"train\"\n",
        "partitioning_version = \"firstpass\"\n",
        "dataset = \"mobile\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_depth = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transect_pths = echofilter.raw.loader.get_partition_list(\n",
        "    partition,\n",
        "    dataset=dataset,\n",
        "    partitioning_version=partitioning_version,\n",
        "    root_data_dir=root_data_dir,\n",
        "    full_path=True,\n",
        "    sharded=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transect_pth = transect_pths[0]\n",
        "with open(os.path.join(transect_pth, \"n_segment.txt\"), \"r\") as f:\n",
        "    n_segment = int(f.readline().strip())\n",
        "\n",
        "i_seg = 0\n",
        "transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
        "    os.path.join(transect_pth, str(i_seg))\n",
        ")\n",
        "transect[\"Sv\"] = transect[\"Sv\"][1:, transect[\"depths\"] <= max_depth]\n",
        "transect[\"Sv\"] = transect[\"Sv\"].astype(np.float32)\n",
        "print(\"mean\", np.mean(transect[\"Sv\"]))\n",
        "print(\"median\", np.median(transect[\"Sv\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.nanpercentile([5, 3, 5, 4, np.nan], 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transect[\"Sv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.distplot(transect[\"Sv\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qs = [0, 0.1, 1, 5, 7, 10, 25, 50, 75, 90, 93, 95, 99, 99.9, 100]\n",
        "ps = np.percentile(transect[\"Sv\"], qs)\n",
        "for q, p in zip(qs, ps):\n",
        "    print(\"{:5.1f} {:7.2f}\".format(q, p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.diff(np.percentile(transect[\"Sv\"], [10, 90])) / 2.56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.diff(np.percentile(transect[\"Sv\"], [7, 93])) / 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.diff(np.percentile(transect[\"Sv\"], [25, 75])) / 1.35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.std(transect[\"Sv\"][1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mad = np.median(np.abs(transect[\"Sv\"] - np.median(transect[\"Sv\"])))\n",
        "print(mad)\n",
        "print(mad * 1.4826)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.percentile(transect[\"Sv\"], [60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.abs(\n",
        "    np.diff(np.percentile(transect[\"Sv\"], [60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10]))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.percentile(transect[\"Sv\"], [40, 35, 30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in tqdm(range(10)):\n",
        "    transect_pth = transect_pths[i]\n",
        "    with open(os.path.join(transect_pth, \"n_segment.txt\"), \"r\") as f:\n",
        "        n_segment = int(f.readline().strip())\n",
        "\n",
        "    i_seg = 0\n",
        "    transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
        "        os.path.join(transect_pth, str(i_seg))\n",
        "    )\n",
        "    transect[\"Sv\"] = transect[\"Sv\"][1:, transect[\"depths\"] <= max_depth]\n",
        "    transect[\"Sv\"] = transect[\"Sv\"].astype(np.float32)\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    sns.distplot(transect[\"Sv\"])\n",
        "    plt.show()\n",
        "\n",
        "    print(\"{:6s} {:7.2f}\".format(\"mean\", np.mean(transect[\"Sv\"])))\n",
        "    print(\"{:6s} {:7.2f}\".format(\"median\", np.median(transect[\"Sv\"])))\n",
        "    print(\"{:6s} {:7.2f}\".format(\"stdev\", np.std(transect[\"Sv\"])))\n",
        "    print(\n",
        "        \"{:6s} {:7.2f}\".format(\n",
        "            \"mad\", np.median(np.abs(transect[\"Sv\"][1:] - np.median(transect[\"Sv\"])))\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"{:6s} {:7.2f}\".format(\n",
        "            \"iqr\", np.diff(np.percentile(transect[\"Sv\"], [25, 75]))[0]\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"{:6s} {:7.2f}\".format(\n",
        "            \"idr\", np.diff(np.percentile(transect[\"Sv\"], [10, 90]))[0]\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"{:6s} {:7.2f}\".format(\n",
        "            \"i7r\", np.diff(np.percentile(transect[\"Sv\"], [7, 93]))[0]\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means = []\n",
        "stdevs = []\n",
        "medians = []\n",
        "mads = []\n",
        "percentiles = []\n",
        "std25 = []\n",
        "\n",
        "qs = [0, 0.1, 1, 5, 7, 10, 15, 20, 25, 30, 35, 40, 50, 75, 90, 93, 95, 99, 99.9, 100]\n",
        "\n",
        "for transect_pth in tqdm(transect_pths):\n",
        "\n",
        "    try:\n",
        "        # Check how many segments the transect was divided into\n",
        "        with open(os.path.join(transect_pth, \"n_segment.txt\"), \"r\") as f:\n",
        "            n_segment = int(f.readline().strip())\n",
        "\n",
        "        for i_seg in range(n_segment):\n",
        "            transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
        "                os.path.join(transect_pth, str(i_seg))\n",
        "            )\n",
        "            transect[\"Sv\"] = transect[\"Sv\"][1:, transect[\"depths\"] <= max_depth]\n",
        "            if len(transect[\"Sv\"]) < 2:\n",
        "                continue\n",
        "            transect[\"Sv\"] = transect[\"Sv\"].astype(np.float32)\n",
        "            means.append(np.nanmean(transect[\"Sv\"]))\n",
        "            stdevs.append(np.nanstd(transect[\"Sv\"]))\n",
        "            median = np.nanmedian(transect[\"Sv\"])\n",
        "            medians.append(median)\n",
        "            mads.append(np.nanmedian(np.abs(transect[\"Sv\"] - median)))\n",
        "            percentiles.append(np.nanpercentile(transect[\"Sv\"], qs))\n",
        "            pc25 = np.nanpercentile(transect[\"Sv\"], 25)\n",
        "            std25.append(np.sqrt(np.nanmean(np.power(transect[\"Sv\"] - pc25, 2))))\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(\"Error loading shard from {}\".format(transect_pth))\n",
        "        print(ex)\n",
        "\n",
        "MEAN = np.nanmean(means)\n",
        "print(\"mean = {}\".format(MEAN))\n",
        "print(\"mean of medians = {}\".format(np.nanmean(medians)))\n",
        "\n",
        "qs = np.array(qs)\n",
        "percentiles = np.array(percentiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variances = []\n",
        "\n",
        "for transect_pth in tqdm(transect_pths):\n",
        "\n",
        "    try:\n",
        "        # Check how many segments the transect was divided into\n",
        "        with open(os.path.join(transect_pth, \"n_segment.txt\"), \"r\") as f:\n",
        "            n_segment = int(f.readline().strip())\n",
        "\n",
        "        for i_seg in range(n_segment):\n",
        "            transect = echofilter.raw.shardloader.load_transect_from_shards_abs(\n",
        "                os.path.join(transect_pth, str(i_seg))\n",
        "            )\n",
        "            transect[\"Sv\"] = transect[\"Sv\"][1:, transect[\"depths\"] <= max_depth]\n",
        "            if len(transect[\"Sv\"]) < 2:\n",
        "                continue\n",
        "            transect[\"Sv\"] = transect[\"Sv\"].astype(np.float32)\n",
        "            variances.append(np.nanmean(np.power(transect[\"Sv\"] - MEAN, 2)))\n",
        "    except Exception as ex:\n",
        "        print(\"Error loading shard from {}\".format(transect_pth))\n",
        "        print(ex)\n",
        "\n",
        "\n",
        "VARIANCE = np.mean(variances)\n",
        "print(\"variance = {}\".format(VARIANCE))\n",
        "print(\"stdev = {}\".format(np.sqrt(VARIANCE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iqrs = (\n",
        "    percentiles[:, np.nonzero(qs == 75)[0][0]]\n",
        "    - percentiles[:, np.nonzero(qs == 25)[0][0]]\n",
        ")\n",
        "IQR = np.mean(iqrs)\n",
        "print(IQR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idrs = (\n",
        "    percentiles[:, np.nonzero(qs == 90)[0][0]]\n",
        "    - percentiles[:, np.nonzero(qs == 10)[0][0]]\n",
        ")\n",
        "IDR = np.mean(idrs)\n",
        "print(IDR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i7rs = (\n",
        "    percentiles[:, np.nonzero(qs == 93)[0][0]]\n",
        "    - percentiles[:, np.nonzero(qs == 7)[0][0]]\n",
        ")\n",
        "I7R = np.mean(i7rs)\n",
        "print(I7R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(np.sqrt(VARIANCE))\n",
        "print(np.mean(stdevs))\n",
        "\n",
        "print(np.mean(mads) * 1.4826)\n",
        "print(IQR / 1.35)\n",
        "print(IDR / 2.56)\n",
        "print(I7R / 3.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\n",
        "    \"{:6s} {:6s}  {:6s}  {:6s}  {:6s}  {:5s}  {:5s}  {:5s}\".format(\n",
        "        \"name\", \"SEM\", \"mean\", \"min\", \"max\", \"pcerr\", \"pcstd\", \"pcran\"\n",
        "    )\n",
        ")\n",
        "for name, estimator in [\n",
        "    (\"mean\", means),\n",
        "    (\"median\", medians),\n",
        "    (\"stdev\", stdevs),\n",
        "    (\"MAD\", mads),\n",
        "    (\"IQR\", iqrs),\n",
        "    (\"IDR\", idrs),\n",
        "    (\"I7R\", i7rs),\n",
        "    (\"std25\", std25),\n",
        "]:\n",
        "    print(\n",
        "        \"{:6s} {:6.4f}  {:6.1f}  {:6.1f}  {:6.1f}  {:5.3f}  {:5.2f}  {:5.1f}\".format(\n",
        "            name,\n",
        "            scipy.stats.sem(estimator),\n",
        "            np.mean(estimator),\n",
        "            np.min(estimator),\n",
        "            np.max(estimator),\n",
        "            scipy.stats.sem(estimator) / np.abs(np.mean(estimator)) * 100,\n",
        "            np.std(estimator) / np.abs(np.mean(estimator)) * 100,\n",
        "            (np.max(estimator) - np.min(estimator)) / np.abs(np.mean(estimator)) * 100,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\n",
        "    \"{:6s}  {:6s}  {:6s}  {:6s}  {:6s}  {:5s}  {:5s}  {:5s}\".format(\n",
        "        \"percentile\", \"SEM\", \"mean\", \"min\", \"max\", \"pcerr\", \"pcstd\", \"pcran\"\n",
        "    )\n",
        ")\n",
        "for iq, q in enumerate(qs):\n",
        "    estimator = percentiles[:, iq]\n",
        "    print(\n",
        "        \"{:10.1f}  {:6.4f}  {:6.1f}  {:6.1f}  {:6.1f}  {:5.3f}  {:5.2f}  {:5.1f}\".format(\n",
        "            q,\n",
        "            scipy.stats.sem(estimator),\n",
        "            np.mean(estimator),\n",
        "            np.min(estimator),\n",
        "            np.max(estimator),\n",
        "            scipy.stats.sem(estimator) / np.abs(np.mean(estimator)) * 100,\n",
        "            np.std(estimator) / np.abs(np.mean(estimator)) * 100,\n",
        "            (np.max(estimator) - np.min(estimator)) / np.abs(np.mean(estimator)) * 100,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(means)\n",
        "plt.title(\"mean estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(medians)\n",
        "plt.title(\"median estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(stdevs)\n",
        "plt.title(\"standard deviation estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(mads)\n",
        "plt.title(\"MAD estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(iqrs)\n",
        "plt.title(\"IQR estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(idrs)\n",
        "plt.title(\"IDR estimates\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "sns.distplot(i7rs)\n",
        "plt.title(\"7-93 estimates\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

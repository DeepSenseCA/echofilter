{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import echofilter.shardloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pth = 'Survey17/Survey17_GR1_S3W_F'\n",
    "timestamps, depths, signals, d_top, d_bot = echofilter.shardloader.load_transect_from_shards(\n",
    "    transect_pth, 100, 800,\n",
    "    root_data_dir='/media/scott/scratch/Datasets/dsforce'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "plt.plot(timestamps, -d_bot, 'b')\n",
    "plt.plot(timestamps, -d_top, 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pth = 'Survey17/Survey17_GR1_S3W_F'\n",
    "timestamps, depths, signals, d_top, d_bot = echofilter.shardloader.load_transect_from_shards(\n",
    "    transect_pth, -100, 800,\n",
    "    root_data_dir='/media/scott/scratch/Datasets/dsforce'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "plt.plot(timestamps, -d_bot, 'b')\n",
    "plt.plot(timestamps, -d_top, 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_pth = 'Survey17/Survey17_GR1_S3W_F'\n",
    "timestamps, depths, signals, d_top, d_bot = echofilter.shardloader.load_transect_from_shards(\n",
    "    transect_pth, 0, 128,\n",
    "    root_data_dir='/media/scott/scratch/Datasets/dsforce'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pcolormesh(timestamps, -depths, signals.T)\n",
    "plt.plot(timestamps, -d_bot, 'b')\n",
    "plt.plot(timestamps, -d_top, 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransectDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            transect_paths,\n",
    "            window_len=128,\n",
    "            num_windows_per_transect=0,\n",
    "            use_dynamic_offsets=True,\n",
    "            transform=None,\n",
    "            root_data_dir=None,\n",
    "            ):\n",
    "        super(TransectDataset, self).__init__()\n",
    "        self.window_len = window_len\n",
    "        self.num_windows = num_windows_per_transect\n",
    "        self.use_dynamic_offsets = use_dynamic_offsets\n",
    "        self.transform = transform\n",
    "        self.root_data_dir = root_data_dir\n",
    "\n",
    "        self.datapoints = []\n",
    "\n",
    "        for transect_path in transect_paths:\n",
    "            # Lookup the number of rows in the transect\n",
    "            # Load the sharding metadata\n",
    "            with open(os.path.join(dirname, 'shard_size.txt'), 'r') as f:\n",
    "                n_timestamps, shard_len = f.readline().strip().split(',')\n",
    "                n_timestamps = int(n_timestamps)\n",
    "            # Generate an array for window centers within the transect\n",
    "            # - if this is for training, we want to randomise the offsets\n",
    "            # - if this is for validation, we want stable windows\n",
    "            num_windows = self.num_windows\n",
    "            if self.num_windows is None or self.num_windows == 0:\n",
    "                # Load enough windows to include all datapoints\n",
    "                num_windows = np.ceil(n_timestamps / self.window_len)\n",
    "            centers = np.linspace(0, n_timestamps, num_windows + 1)[:num_windows]\n",
    "            if self.use_dynamic_offsets:\n",
    "                if len(centers) > 1:\n",
    "                    max_dy_offset = centers[1] - centers[0]\n",
    "                else:\n",
    "                    max_dy_offset = n_timestamps\n",
    "                centers += np.random.rand() * max_dy_offset\n",
    "            centers = np.round(centers)\n",
    "            # Add each (transect, center) to the list for this epoch\n",
    "            for center_idx in centers:\n",
    "                self.datapoints.append((transect_path, int(center_idx)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        transect_pth, center_idx = self.datapoints[index]\n",
    "        # Load data from shards\n",
    "        timestamps, depths, signals, d_top, d_bot = echofilter.shardloader.load_transect_from_shards(\n",
    "            transect_pth,\n",
    "            center_idx - int(self.window_len / 2),\n",
    "            center_idx - int(self.window_len / 2) + self.window_len,\n",
    "            root_data_dir=self.root_data_dir,\n",
    "        )\n",
    "        # Convert lines to masks\n",
    "        ddepths = np.broadcast_to(depths, signals.shape)\n",
    "        mask_top = ddepths < np.expand_dims(d_top, -1)\n",
    "        mask_bot = ddepths > np.expand_dims(d_bot, -1)\n",
    "        if self.transform is not None:\n",
    "            signals, mask_top, mask_bot = self.transform(signals, mask_top, mask_bot)\n",
    "        return signals, mask_top, mask_bot\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransectDataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

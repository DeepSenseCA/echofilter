
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>echofilter.optim package &#8212; Echofilter 1.0.dev0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="echofilter.raw package" href="echofilter.raw.html" />
    <link rel="prev" title="echofilter.nn.modules package" href="echofilter.nn.modules.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Echofilter 1.0.dev0 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../usage_guide.html">
   Usage Guide
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../programs/programs.html">
   CLI Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../programs/inference.html">
     echofilter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../programs/ev2csv.html">
     ev2csv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../programs/train.html">
     echofilter-train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../programs/generate_shards.html">
     echofilter-generate-shards
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="modules.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="echofilter.html">
     echofilter package
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="echofilter.data.html">
       echofilter.data package
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="echofilter.nn.html">
       echofilter.nn package
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="echofilter.nn.modules.html">
         echofilter.nn.modules package
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       echofilter.optim package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="echofilter.raw.html">
       echofilter.raw package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="echofilter.ui.html">
       echofilter.ui package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="echofilter.win.html">
       echofilter.win package
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../py-modindex.html">
   Module Index
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/source/packages/echofilter.optim.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.criterions">
   echofilter.optim.criterions module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.meters">
   echofilter.optim.meters module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.schedulers">
   echofilter.optim.schedulers module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.torch_backports">
   echofilter.optim.torch_backports module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.utils">
   echofilter.optim.utils module
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>echofilter.optim package</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.criterions">
   echofilter.optim.criterions module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.meters">
   echofilter.optim.meters module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.schedulers">
   echofilter.optim.schedulers module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.torch_backports">
   echofilter.optim.torch_backports module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-echofilter.optim.utils">
   echofilter.optim.utils module
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="section" id="module-echofilter.optim">
<span id="echofilter-optim-package"></span><h1>echofilter.optim package<a class="headerlink" href="#module-echofilter.optim" title="Permalink to this headline">#</a></h1>
<p>Optimization, criterions and metrics.</p>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">#</a></h2>
</div>
<div class="section" id="module-echofilter.optim.criterions">
<span id="echofilter-optim-criterions-module"></span><h2>echofilter.optim.criterions module<a class="headerlink" href="#module-echofilter.optim.criterions" title="Permalink to this headline">#</a></h2>
<p>Evaluation criterions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_accuracy">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_accuracy" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the fraction of input which exceeds a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Target tensor, the same shape as <cite>input</cite>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> and <cite>target</cite> must exceed to be
binarised as the positive class. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The fraction of <cite>input</cite> which has the same class as <cite>target</cite> after
thresholding.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_accuracy_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_accuracy_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_accuracy_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_accuracy_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the accuracy between input and target, after passing <cite>input</cite>
through a sigmoid function.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_accuracy" title="echofilter.optim.criterions.mask_accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_accuracy</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_active_fraction">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_active_fraction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_active_fraction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_active_fraction" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the fraction of input which exceeds a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> must exceed. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The fraction of <cite>input</cite> which exceeds <cite>threshold</cite>, with shaped
corresponding to <cite>reduction</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_active_fraction_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_active_fraction_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_active_fraction_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_active_fraction_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Convert logits to probabilities with sigmoid, then measure the fraction
of the tensor which exceeds a threshold.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_active_fraction" title="echofilter.optim.criterions.mask_active_fraction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_active_fraction</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_f1_score">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_f1_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_f1_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_f1_score" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the F1-score of the input as compared to a ground truth target,
after binarising with a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Target tensor, the same shape as <cite>input</cite>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> and <cite>target</cite> must exceed to be
binarised as the positive class. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The F1-score of <cite>input</cite> as compared to <cite>target</cite> after thresholding.
The F1-score is the harmonic mean of precision and recall.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_precision" title="echofilter.optim.criterions.mask_precision"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_precision</span></code></a>, <a class="reference internal" href="#echofilter.optim.criterions.mask_recall" title="echofilter.optim.criterions.mask_recall"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_recall</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_f1_score_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_f1_score_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_f1_score_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_f1_score_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Convert logits to probabilities with sigmoid, apply a threshold, then
measure the F1-score of the tensor as compared to ground truth.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_f1_score" title="echofilter.optim.criterions.mask_f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_f1_score</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_jaccard_index">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_jaccard_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_jaccard_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_jaccard_index" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the Jaccard Index (intersection over union) of the input as
compared to a ground truth target, after binarising with a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Target tensor, the same shape as <cite>input</cite>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> and <cite>target</cite> must exceed to be
binarised as the positive class. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Jaccard Index of <cite>input</cite> as compared to <cite>target</cite>.
The Jaccard Index is the number of elements where both <cite>input</cite> and
<cite>target</cite> exceed <cite>threshold</cite>, divided by the number of elements where
at least one of <cite>input</cite> and <cite>target</cite> exceeds <cite>threshold</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_jaccard_index_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_jaccard_index_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_jaccard_index_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_jaccard_index_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Convert logits to probabilities with sigmoid, apply a threshold, then
measure the Jaccard Index (intersection over union) of the tensor as
compared to ground truth.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_jaccard_index" title="echofilter.optim.criterions.mask_jaccard_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_jaccard_index</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_precision">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_precision" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the precision of the input as compared to a ground truth target,
after binarising with a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Target tensor, the same shape as <cite>input</cite>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> and <cite>target</cite> must exceed to be
binarised as the positive class. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The precision of <cite>input</cite> as compared to <cite>target</cite> after thresholding.
The fraction of predicted positive cases, <cite>input &gt; 0.5</cite>, which are
true positive cases (<cite>input &gt; 0.5 and `target &gt; 0.5</cite>).
If there are no predicted positives, the output is <cite>0</cite> if there are
any positives to predict and <cite>1</cite> if there are none.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_precision_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_precision_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_precision_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_precision_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Convert logits to probabilities with sigmoid, apply a threshold, then
measure the precision of the tensor as compared to ground truth.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_precision" title="echofilter.optim.criterions.mask_precision"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_precision</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_recall">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_recall" title="Permalink to this definition">#</a></dt>
<dd><p>Measure the recall of the input as compared to a ground truth target,
after binarising with a threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Input tensor.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)"><em>torch.Tensor</em></a>) – Target tensor, the same shape as <cite>input</cite>.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em>, </em><em>optional</em>) – Threshold which entries in <cite>input</cite> and <cite>target</cite> must exceed to be
binarised as the positive class. Default is <cite>0.5</cite>.</p></li>
<li><p><strong>ndim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a><em> or </em><em>None</em>) – Number of dimensions to keep. If <cite>None</cite>, only the first (batch)
dimension is kept and the rest are flattened. Default is <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<cite>“none”</cite> or <cite>“mean”</cite> or <cite>“sum”</cite>, optional) – Specifies the reduction to apply to the output:
<cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>.
<cite>“none”</cite>: no reduction will be applied,
<cite>“mean”</cite>: the sum of the output will be divided by the number of
elements in the output,
<cite>“sum”</cite>: the output will be summed.
Default: <cite>“mean”</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The recall of <cite>input</cite> as compared to <cite>target</cite> after thresholding.
The fraction of true positive cases, <cite>target &gt; 0.5</cite>, which are
true positive cases (<cite>input &gt; 0.5 and `target &gt; 0.5</cite>).
If there are no true positives, the output is <cite>1</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.11.0)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.criterions.mask_recall_with_logits">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.criterions.</span></span><span class="sig-name descname"><span class="pre">mask_recall_with_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/criterions.html#mask_recall_with_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.criterions.mask_recall_with_logits" title="Permalink to this definition">#</a></dt>
<dd><p>Convert logits to probabilities with sigmoid, apply a threshold, then
measure the recall of the tensor as compared to ground truth.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#echofilter.optim.criterions.mask_recall" title="echofilter.optim.criterions.mask_recall"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_recall</span></code></a></p>
</div>
</dd></dl>

</div>
<div class="section" id="module-echofilter.optim.meters">
<span id="echofilter-optim-meters-module"></span><h2>echofilter.optim.meters module<a class="headerlink" href="#module-echofilter.optim.meters" title="Permalink to this headline">#</a></h2>
<p>Meters</p>
<dl class="py class">
<dt class="sig sig-object py" id="echofilter.optim.meters.AverageMeter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">echofilter.optim.meters.</span></span><span class="sig-name descname"><span class="pre">AverageMeter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">':f'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/meters.html#AverageMeter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.meters.AverageMeter" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Computes and stores the average and current value</p>
<dl class="py method">
<dt class="sig sig-object py" id="echofilter.optim.meters.AverageMeter.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/meters.html#AverageMeter.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.meters.AverageMeter.reset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="echofilter.optim.meters.AverageMeter.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/meters.html#AverageMeter.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.meters.AverageMeter.update" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="echofilter.optim.meters.ProgressMeter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">echofilter.optim.meters.</span></span><span class="sig-name descname"><span class="pre">ProgressMeter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_batches</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">meters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/meters.html#ProgressMeter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.meters.ProgressMeter" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="echofilter.optim.meters.ProgressMeter.display">
<span class="sig-name descname"><span class="pre">display</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/meters.html#ProgressMeter.display"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.meters.ProgressMeter.display" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-echofilter.optim.schedulers">
<span id="echofilter-optim-schedulers-module"></span><h2>echofilter.optim.schedulers module<a class="headerlink" href="#module-echofilter.optim.schedulers" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="echofilter.optim.schedulers.MesaOneCycleLR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">echofilter.optim.schedulers.</span></span><span class="sig-name descname"><span class="pre">MesaOneCycleLR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.75</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/schedulers.html#MesaOneCycleLR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.schedulers.MesaOneCycleLR" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#echofilter.optim.torch_backports.OneCycleLR" title="echofilter.optim.torch_backports.OneCycleLR"><code class="xref py py-class docutils literal notranslate"><span class="pre">echofilter.optim.torch_backports.OneCycleLR</span></code></a></p>
<p>A variant on the 1cycle learning rate policy which features a flat
region at maximum learning rate between warm-up and warm-down.</p>
<p>Sets the learning rate of each parameter group according to the
1cycle learning rate policy. The 1cycle policy anneals the learning
rate from an initial learning rate to some maximum learning rate and then
from that maximum learning rate to some minimum learning rate much lower
than the initial learning rate.
This policy was initially described in the paper <a class="reference external" href="https://arxiv.org/abs/1708.07120">Super-Convergence:
Very Fast Training of Neural Networks Using Large Learning Rates</a>.</p>
<p>The 1cycle learning rate policy changes the learning rate after every batch.
<cite>step</cite> should be called after a batch has been used for training.</p>
<p>This scheduler is not chainable.</p>
<p>Note also that the total number of steps in the cycle can be determined in one
of two ways (listed in order of precedence):</p>
<ol class="arabic simple">
<li><p>A value for total_steps is explicitly provided.</p></li>
<li><p>A number of epochs (epochs) and a number of steps per epoch
(steps_per_epoch) are provided.
In this case, the number of total steps is inferred by
total_steps = epochs * steps_per_epoch</p></li>
</ol>
<p>You must either provide a value for total_steps or provide a value for both
epochs and steps_per_epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Wrapped optimizer.</p></li>
<li><p><strong>max_lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Upper learning rate boundaries in the cycle
for each parameter group.</p></li>
<li><p><strong>total_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The total number of steps in the cycle. Note that
if a value is provided here, then it must be inferred by providing
a value for epochs and steps_per_epoch.
Default: None</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The number of epochs to train for. This is used along
with steps_per_epoch in order to infer the total number of steps in the cycle
if a value for total_steps is not provided.
Default: None</p></li>
<li><p><strong>steps_per_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The number of steps per epoch to train for. This is
used along with epochs in order to infer the total number of steps in the
cycle if a value for total_steps is not provided.
Default: None</p></li>
<li><p><strong>pct_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – The percentage of the cycle (in number of steps) spent
increasing the learning rate.
Default: 0.25</p></li>
<li><p><strong>pct_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – The percentage of the cycle (in number of steps) spent
before decreasing the learning rate.
Default: 0.75</p></li>
<li><p><strong>anneal_strategy</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><em>str</em></a>) – {“cos”, “linear”}
Specifies the annealing strategy: “cos” for cosine annealing, “linear” for
linear annealing.
Default: “cos”.</p></li>
<li><p><strong>cycle_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, momentum is cycled inversely
to learning rate between “base_momentum” and “max_momentum”.
Default: True</p></li>
<li><p><strong>base_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Lower momentum boundaries in the cycle
for each parameter group. Note that momentum is cycled inversely
to learning rate; at the peak of a cycle, momentum is
“base_momentum” and learning rate is “max_lr”.
Default: 0.85</p></li>
<li><p><strong>max_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Upper momentum boundaries in the cycle
for each parameter group. Functionally,
it defines the cycle amplitude (max_momentum - base_momentum).
Note that momentum is cycled inversely
to learning rate; at the start of a cycle, momentum is “max_momentum”
and learning rate is “base_lr”
Default: 0.95</p></li>
<li><p><strong>div_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – Determines the initial learning rate via
initial_lr = max_lr/div_factor
Default: 25</p></li>
<li><p><strong>final_div_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – Determines the minimum learning rate via
min_lr = initial_lr/final_div_factor
Default: 1e4</p></li>
<li><p><strong>last_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The index of the last batch. This parameter is used when
resuming a training job. Since <cite>step()</cite> should be invoked after each
batch instead of after each epoch, this number represents the total
number of <em>batches</em> computed, not the total number of epochs computed.
When last_epoch=-1, the schedule is started from the beginning.
Default: -1</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">MesaOneCycleLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">train_batch</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="echofilter.optim.schedulers.MesaOneCycleLR.get_lr">
<span class="sig-name descname"><span class="pre">get_lr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/schedulers.html#MesaOneCycleLR.get_lr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.schedulers.MesaOneCycleLR.get_lr" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-echofilter.optim.torch_backports">
<span id="echofilter-optim-torch-backports-module"></span><h2>echofilter.optim.torch_backports module<a class="headerlink" href="#module-echofilter.optim.torch_backports" title="Permalink to this headline">#</a></h2>
<p>This contains functions copied from newer versions of pytorch than v1.2.0,
which is the latest version currently available from IBM compiled for ppc64
architectures.</p>
<p>From PyTorch:</p>
<p>Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)
Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)</p>
<p>From Caffe2:</p>
<p>Copyright (c) 2016-present, Facebook Inc. All rights reserved.</p>
<p>All contributions by Facebook:
Copyright (c) 2016 Facebook Inc.</p>
<p>All contributions by Google:
Copyright (c) 2015 Google Inc.
All rights reserved.</p>
<p>All contributions by Yangqing Jia:
Copyright (c) 2015 Yangqing Jia
All rights reserved.</p>
<p>All contributions from Caffe:
Copyright(c) 2013, 2014, 2015, the respective contributors
All rights reserved.</p>
<p>All other contributions:
Copyright(c) 2015, 2016 the respective contributors
All rights reserved.</p>
<p>Caffe2 uses a copyright model similar to Caffe: each contributor holds
copyright over their contributions to Caffe2. The project versioning records
all such contribution and copyright details. If a contributor wants to further
mark their specific copyright on a particular contribution, they should
indicate their copyright solely in the commit message of the change when it is
committed.</p>
<p>All rights reserved.</p>
<p>Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:</p>
<ol class="arabic simple">
<li><p>Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.</p></li>
<li><p>Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.</p></li>
<li><p>Neither the names of Facebook, Deepmind Technologies, NYU, NEC Laboratories America
and IDIAP Research Institute nor the names of its contributors may be
used to endorse or promote products derived from this software without
specific prior written permission.</p></li>
</ol>
<p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS”
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.</p>
<dl class="py class">
<dt class="sig sig-object py" id="echofilter.optim.torch_backports.OneCycleLR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">echofilter.optim.torch_backports.</span></span><span class="sig-name descname"><span class="pre">OneCycleLR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps_per_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anneal_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cos'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.85</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">div_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_div_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/torch_backports.html#OneCycleLR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.torch_backports.OneCycleLR" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">echofilter.optim.torch_backports._LRScheduler</span></code></p>
<p>Backported from pytorch 1.4.0.</p>
<p>Sets the learning rate of each parameter group according to the
1cycle learning rate policy. The 1cycle policy anneals the learning
rate from an initial learning rate to some maximum learning rate and then
from that maximum learning rate to some minimum learning rate much lower
than the initial learning rate.
This policy was initially described in the paper <a class="reference external" href="https://arxiv.org/abs/1708.07120">Super-Convergence:
Very Fast Training of Neural Networks Using Large Learning Rates</a>.</p>
<p>The 1cycle learning rate policy changes the learning rate after every batch.
<cite>step</cite> should be called after a batch has been used for training.</p>
<p>This scheduler is not chainable.</p>
<p>Note also that the total number of steps in the cycle can be determined in one
of two ways (listed in order of precedence):</p>
<ol class="arabic simple">
<li><p>A value for total_steps is explicitly provided.</p></li>
<li><p>A number of epochs (epochs) and a number of steps per epoch
(steps_per_epoch) are provided.
In this case, the number of total steps is inferred by
total_steps = epochs * steps_per_epoch</p></li>
</ol>
<p>You must either provide a value for total_steps or provide a value for both
epochs and steps_per_epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Wrapped optimizer.</p></li>
<li><p><strong>max_lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Upper learning rate boundaries in the cycle
for each parameter group.</p></li>
<li><p><strong>total_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The total number of steps in the cycle. Note that
if a value is provided here, then it must be inferred by providing
a value for epochs and steps_per_epoch.
Default: None</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The number of epochs to train for. This is used along
with steps_per_epoch in order to infer the total number of steps in the cycle
if a value for total_steps is not provided.
Default: None</p></li>
<li><p><strong>steps_per_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The number of steps per epoch to train for. This is
used along with epochs in order to infer the total number of steps in the
cycle if a value for total_steps is not provided.
Default: None</p></li>
<li><p><strong>pct_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – The percentage of the cycle (in number of steps) spent
increasing the learning rate.
Default: 0.3</p></li>
<li><p><strong>anneal_strategy</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><em>str</em></a>) – {‘cos’, ‘linear’}
Specifies the annealing strategy: “cos” for cosine annealing, “linear” for
linear annealing.
Default: ‘cos’</p></li>
<li><p><strong>cycle_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, momentum is cycled inversely
to learning rate between ‘base_momentum’ and ‘max_momentum’.
Default: True</p></li>
<li><p><strong>base_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Lower momentum boundaries in the cycle
for each parameter group. Note that momentum is cycled inversely
to learning rate; at the peak of a cycle, momentum is
‘base_momentum’ and learning rate is ‘max_lr’.
Default: 0.85</p></li>
<li><p><strong>max_momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><em>list</em></a>) – Upper momentum boundaries in the cycle
for each parameter group. Functionally,
it defines the cycle amplitude (max_momentum - base_momentum).
Note that momentum is cycled inversely
to learning rate; at the start of a cycle, momentum is ‘max_momentum’
and learning rate is ‘base_lr’
Default: 0.95</p></li>
<li><p><strong>div_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – Determines the initial learning rate via
initial_lr = max_lr/div_factor
Default: 25</p></li>
<li><p><strong>final_div_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – Determines the minimum learning rate via
min_lr = initial_lr/final_div_factor
Default: 1e4</p></li>
<li><p><strong>last_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The index of the last batch. This parameter is used when
resuming a training job. Since <cite>step()</cite> should be invoked after each
batch instead of after each epoch, this number represents the total
number of <em>batches</em> computed, not the total number of epochs computed.
When last_epoch=-1, the schedule is started from the beginning.
Default: -1</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">train_batch</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="echofilter.optim.torch_backports.OneCycleLR.get_lr">
<span class="sig-name descname"><span class="pre">get_lr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/torch_backports.html#OneCycleLR.get_lr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.torch_backports.OneCycleLR.get_lr" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-echofilter.optim.utils">
<span id="echofilter-optim-utils-module"></span><h2>echofilter.optim.utils module<a class="headerlink" href="#module-echofilter.optim.utils" title="Permalink to this headline">#</a></h2>
<p>Utility functions for interacting with optimizers.</p>
<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.utils.get_current_lr">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.utils.</span></span><span class="sig-name descname"><span class="pre">get_current_lr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/utils.html#get_current_lr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.utils.get_current_lr" title="Permalink to this definition">#</a></dt>
<dd><p>Get the learning rate of an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.11.0)"><em>torch.optim.Optimizer</em></a>) – An optimizer, with a learning rate common to all parameter groups.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The learning rate of the first parameter group.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="echofilter.optim.utils.get_current_momentum">
<span class="sig-prename descclassname"><span class="pre">echofilter.optim.utils.</span></span><span class="sig-name descname"><span class="pre">get_current_momentum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/echofilter/optim/utils.html#get_current_momentum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#echofilter.optim.utils.get_current_momentum" title="Permalink to this definition">#</a></dt>
<dd><p>Get the momentum of an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v1.11.0)"><em>torch.optim.Optimizer</em></a>) – An optimizer which implements momentum or betas (where momentum is the
first beta, c.f. <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="(in PyTorch v1.11.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code></a>) with a momentum common to all
parameter groups.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The momentum of the first parameter group.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)">float</a></p>
</dd>
</dl>
</dd></dl>

</div>
</div>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="echofilter.nn.modules.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">echofilter.nn.modules package</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="echofilter.raw.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">echofilter.raw package</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Scott C. Lowe<br/>
  
      &copy; Copyright 2022, Scott C. Lowe.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>
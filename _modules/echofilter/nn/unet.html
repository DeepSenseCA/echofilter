
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>echofilter.nn.unet &#8212; Echofilter 1.0.dev0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Echofilter 1.0.dev0 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/usage_guide.html">
   Usage Guide
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../source/programs/programs.html">
   CLI Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../source/programs/inference.html">
     echofilter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../source/programs/ev2csv.html">
     ev2csv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../source/programs/train.html">
     echofilter-train
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../source/programs/generate_shards.html">
     echofilter-generate-shards
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../source/packages/modules.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../source/packages/echofilter.html">
     echofilter package
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../source/packages/echofilter.data.html">
       echofilter.data package
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../source/packages/echofilter.nn.html">
       echofilter.nn package
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../source/packages/echofilter.nn.modules.html">
         echofilter.nn.modules package
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../source/packages/echofilter.optim.html">
       echofilter.optim package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../source/packages/echofilter.raw.html">
       echofilter.raw package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../source/packages/echofilter.ui.html">
       echofilter.ui package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../source/packages/echofilter.win.html">
       echofilter.win package
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../source/changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../py-modindex.html">
   Module Index
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for echofilter.nn.unet</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">U-Net model.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># This file is part of Echofilter.</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2020-2022  Scott C. Lowe and Offshore Energy Research Association (OERA)</span>
<span class="c1">#</span>
<span class="c1"># This program is free software: you can redistribute it and/or modify</span>
<span class="c1"># it under the terms of the GNU Affero General Public License as</span>
<span class="c1"># published by the Free Software Foundation, version 3.</span>
<span class="c1">#</span>
<span class="c1"># This program is distributed in the hope that it will be useful,</span>
<span class="c1"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c1"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c1"># GNU Affero General Public License for more details.</span>
<span class="c1">#</span>
<span class="c1"># You should have received a copy of the GNU Affero General Public License</span>
<span class="c1"># along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.</span>

<span class="kn">import</span> <span class="nn">functools</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">modules</span>


<div class="viewcode-block" id="Down"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.Down">[docs]</a><span class="k">class</span> <span class="nc">Down</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Downscaling layer, downsampling by a factor of two in one or more dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">compress_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Down</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">compress_dims</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span><span class="n">compress_dims</span><span class="p">)</span>
        <span class="n">kernel_sizes</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span>
            <span class="mi">2</span> <span class="k">if</span> <span class="n">compress_dim</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">compress_dim</span> <span class="ow">in</span> <span class="n">compress_dims</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_sizes</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;avg&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported pooling method: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>

<div class="viewcode-block" id="Down.forward"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.Down.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Up"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.Up">[docs]</a><span class="k">class</span> <span class="nc">Up</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Upscaling layer, upsampling by a factor of two in one or more dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">up_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Up</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">up_dims</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span><span class="n">up_dims</span><span class="p">)</span>
        <span class="n">kernel_sizes</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">up_dim</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">up_dim</span> <span class="ow">in</span> <span class="n">up_dims</span><span class="p">)</span>

        <span class="c1"># If conv mode, use a transposed convolution to increase the size</span>
        <span class="c1"># Otherwise, use one of the nn.Upsample modes:</span>
        <span class="c1"># {&quot;nearest&quot;, &quot;linear&quot;, &quot;bilinear&quot;, &quot;bicubic&quot;}</span>
        <span class="k">if</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Number of channels must be provided if upscaling with &quot;</span>
                    <span class="s2">&quot;transposed convolution.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="p">,</span>
                <span class="n">in_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_sizes</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="n">kernel_sizes</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span>
                <span class="n">scale_factor</span><span class="o">=</span><span class="n">kernel_sizes</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

<div class="viewcode-block" id="Up.forward"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.Up.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="UNetBlock"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.UNetBlock">[docs]</a><span class="k">class</span> <span class="nc">UNetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a (cascading set of) UNet block(s).</span>

<span class="sd">    Each block performs the steps:</span>
<span class="sd">        - Store input to be used in skip connection</span>
<span class="sd">        - Down step</span>
<span class="sd">        - Horizontal block</span>
<span class="sd">        - &lt;Recursion&gt;</span>
<span class="sd">        - Up step</span>
<span class="sd">        - Concatenate with skip connection</span>
<span class="sd">        - Horizontal block</span>

<span class="sd">    Where &lt;Recursion&gt; is a call generating a child UNetBlock instance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_channels : int</span>
<span class="sd">        Number of input channels to this block.</span>
<span class="sd">    horizontal_block_factory : callable</span>
<span class="sd">        A :class:`torch.nn.Module` constructor or function which returns a</span>
<span class="sd">        block of layers. The resulting module must accept `in_channels` and</span>
<span class="sd">        `out_channels` as its first two arguments.</span>
<span class="sd">    n_block : int, optional</span>
<span class="sd">        The number of nested UNetBlocks to use. Default is `1` (no nesting).</span>
<span class="sd">    block_expansion_factor : int or float, optional</span>
<span class="sd">        Expansion factor for the number of channels between nested UNetBlocks.</span>
<span class="sd">        Default is `2`.</span>
<span class="sd">    expand_only_on_down : bool, optional</span>
<span class="sd">        Whether to exand the number of channels only when one of the spatial</span>
<span class="sd">        dimensions is compressed. Default is `False`.</span>
<span class="sd">    blocks_per_downsample : int or sequence, optional</span>
<span class="sd">        How many blocks to include between each downsample operation. This can</span>
<span class="sd">        be a tuple of values for each spatial dimension, or an int which</span>
<span class="sd">        uses the same value for each spatial dimension. Default is `1`.</span>
<span class="sd">    blocks_before_first_downsample : int or sequence, optional</span>
<span class="sd">        How many blocks to include before the first spatial downsampling</span>
<span class="sd">        occurs. Default is `1`.</span>
<span class="sd">    always_include_skip_connection : bool, optional</span>
<span class="sd">        If `True`, a skip connection is included even if no dimensions were</span>
<span class="sd">        downsampled in this block. Default is `True`.</span>
<span class="sd">    deepest_inner : {callable, &quot;horizontal_block&quot;, &quot;identity&quot;, None}, optional</span>
<span class="sd">        A layer which should be applied at the deepest part of the network,</span>
<span class="sd">        before the first upsampling step. The parameter should either be a</span>
<span class="sd">        pre-instantiated layer, or the string `&quot;horizontal_block&quot;`, to indicate</span>
<span class="sd">        an additional block as generated by the `horizontal_block_factory`.</span>
<span class="sd">        If it is the string `&quot;identity&quot;` or `None` (default), no additional</span>
<span class="sd">        layer is included at the deepest point before upsampling begins.</span>
<span class="sd">    downsampling_modes : {&quot;max&quot;, &quot;avg&quot;, &quot;stride&quot;} or sequence, optional</span>
<span class="sd">        The downsampling mode to use. If this is a string, the same</span>
<span class="sd">        downsampling mode is used for every downsampling step. If it is</span>
<span class="sd">        a sequence, it should contain a string for each downsampling step.</span>
<span class="sd">        If the input sequence is too short, the final value will be used</span>
<span class="sd">        for all remaining downsampling steps. Default is `&quot;max&quot;`.</span>
<span class="sd">    upsampling_modes : str or sequence, optional</span>
<span class="sd">        The upsampling mode to use. If this is a string, it must be `&quot;conv&quot;`,</span>
<span class="sd">        or something supported by :class:`torch.nn.Upsample`; the same</span>
<span class="sd">        upsampling mode is used for every upsampling step. If it is</span>
<span class="sd">        a sequence, it should contain a string for each upsampling step.</span>
<span class="sd">        If the input sequence is too short, the final value will be used</span>
<span class="sd">        for all remaining upsampling steps. Default is `&quot;bilinear&quot;`.</span>
<span class="sd">    _i_block : int, optional</span>
<span class="sd">        The current block number. Used internally to track recursion.</span>
<span class="sd">        Default is `0`.</span>
<span class="sd">    _i_down : int, optional</span>
<span class="sd">        Used internally to track downsampling depth. Default is `0`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This class is defined recursively, and will instantiate itself as its own</span>
<span class="sd">    child until the number of blocks has been satisfied.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">,</span>
        <span class="n">horizontal_block_factory</span><span class="p">,</span>
        <span class="n">n_block</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">block_expansion_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">expand_only_on_down</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">blocks_per_downsample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">blocks_before_first_downsample</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">always_include_skip_connection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">deepest_inner</span><span class="o">=</span><span class="s2">&quot;identity&quot;</span><span class="p">,</span>
        <span class="n">downsampling_modes</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
        <span class="n">upsampling_modes</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
        <span class="n">_i_block</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">_i_down</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UNetBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Ensure these variables are a tuple of length two</span>
        <span class="n">blocks_per_downsample</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span><span class="n">blocks_per_downsample</span><span class="p">)</span>
        <span class="n">blocks_before_first_downsample</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span>
            <span class="n">blocks_before_first_downsample</span>
        <span class="p">)</span>

        <span class="c1"># Check which downsampling and upsampling mode we are using for this</span>
        <span class="c1"># layer (may be the same for every layer)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">downsampling_modes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">downsampling_mode</span> <span class="o">=</span> <span class="n">downsampling_modes</span>
        <span class="k">elif</span> <span class="n">_i_down</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">downsampling_modes</span><span class="p">):</span>
            <span class="n">downsampling_mode</span> <span class="o">=</span> <span class="n">downsampling_modes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">downsampling_mode</span> <span class="o">=</span> <span class="n">downsampling_modes</span><span class="p">[</span><span class="n">_i_down</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">upsampling_modes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">upsampling_mode</span> <span class="o">=</span> <span class="n">upsampling_modes</span>
        <span class="k">elif</span> <span class="n">_i_down</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">upsampling_modes</span><span class="p">):</span>
            <span class="n">upsampling_mode</span> <span class="o">=</span> <span class="n">upsampling_modes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">upsampling_mode</span> <span class="o">=</span> <span class="n">upsampling_modes</span><span class="p">[</span><span class="n">_i_down</span><span class="p">]</span>

        <span class="c1"># Check which dimensions need to be compressed with this block</span>
        <span class="n">compress_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">_i_block</span> <span class="o">&gt;=</span> <span class="n">i0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">_i_block</span> <span class="o">-</span> <span class="n">i0</span><span class="p">)</span> <span class="o">%</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i0</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks_before_first_downsample</span><span class="p">,</span> <span class="n">blocks_per_downsample</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">compress_any_dims</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">compress_dims</span><span class="p">)</span>

        <span class="c1"># Determine whether we are increasing the number of channels, and</span>
        <span class="c1"># if so what to</span>
        <span class="k">if</span> <span class="n">expand_only_on_down</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">compress_any_dims</span><span class="p">:</span>
            <span class="n">out_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">block_expansion_factor</span><span class="p">)))</span>

        <span class="c1"># Downsamling step. If the mode is &quot;stride&quot;, this is incorporated</span>
        <span class="c1"># into the horizontal block with a strided convolution. If there</span>
        <span class="c1"># is no need to downsample, it will be the Identity function.</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">compress_any_dims</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">downsampling_mode</span> <span class="o">==</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">compress_dim</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">compress_dim</span> <span class="ow">in</span> <span class="n">compress_dims</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">Down</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">downsampling_mode</span><span class="p">,</span> <span class="n">compress_dims</span><span class="o">=</span><span class="n">compress_dims</span><span class="p">)</span>

        <span class="c1"># First horizontal block. It might begin with a downsampling stride,</span>
        <span class="c1"># and might increase the number of channels.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">horizontal_block_a</span> <span class="o">=</span> <span class="n">horizontal_block_factory</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># In the sequence, the inner step comes next. But we will define it</span>
        <span class="c1"># once we have finished defining everything else in this UNet block.</span>

        <span class="c1"># Upsampling step. Does the inverse of the Down step, using some</span>
        <span class="c1"># method.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">compress_any_dims</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">Up</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">up_dims</span><span class="o">=</span><span class="n">compress_dims</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">upsampling_mode</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">compress_any_dims</span> <span class="ow">or</span> <span class="n">always_include_skip_connection</span><span class="p">:</span>
            <span class="c1"># Concatenation step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">concatenate</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">FlexibleConcat2d</span><span class="p">()</span>
            <span class="n">b_in_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="o">+</span> <span class="n">out_channels</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No concatenation step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">concatenate</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">b_in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>

        <span class="c1"># Second horizontal block. Takes both the skip connection and the</span>
        <span class="c1"># upsampled data as its input.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">horizontal_block_b</span> <span class="o">=</span> <span class="n">horizontal_block_factory</span><span class="p">(</span><span class="n">b_in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_i_block</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">n_block</span><span class="p">:</span>
            <span class="c1"># Recurse deeper! Call this class again, but with the</span>
            <span class="c1"># block counter increased.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nested</span> <span class="o">=</span> <span class="n">UNetBlock</span><span class="p">(</span>
                <span class="n">out_channels</span><span class="p">,</span>
                <span class="n">horizontal_block_factory</span><span class="p">,</span>
                <span class="n">n_block</span><span class="o">=</span><span class="n">n_block</span><span class="p">,</span>
                <span class="n">block_expansion_factor</span><span class="o">=</span><span class="n">block_expansion_factor</span><span class="p">,</span>
                <span class="n">expand_only_on_down</span><span class="o">=</span><span class="n">expand_only_on_down</span><span class="p">,</span>
                <span class="n">blocks_per_downsample</span><span class="o">=</span><span class="n">blocks_per_downsample</span><span class="p">,</span>
                <span class="n">blocks_before_first_downsample</span><span class="o">=</span><span class="n">blocks_before_first_downsample</span><span class="p">,</span>
                <span class="n">always_include_skip_connection</span><span class="o">=</span><span class="n">always_include_skip_connection</span><span class="p">,</span>
                <span class="n">deepest_inner</span><span class="o">=</span><span class="n">deepest_inner</span><span class="p">,</span>
                <span class="n">downsampling_modes</span><span class="o">=</span><span class="n">downsampling_modes</span><span class="p">,</span>
                <span class="n">upsampling_modes</span><span class="o">=</span><span class="n">upsampling_modes</span><span class="p">,</span>
                <span class="n">_i_block</span><span class="o">=</span><span class="n">_i_block</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">_i_down</span><span class="o">=</span><span class="n">_i_down</span> <span class="o">+</span> <span class="n">compress_any_dims</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">deepest_inner</span><span class="p">,</span> <span class="s2">&quot;__call__&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nested</span> <span class="o">=</span> <span class="n">deepest_inner</span>
        <span class="k">elif</span> <span class="n">deepest_inner</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">deepest_inner</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;identity&quot;</span><span class="p">:</span>
            <span class="c1"># End recursion, by doing nothing for the inner loop.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nested</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">deepest_inner</span> <span class="o">==</span> <span class="s2">&quot;horizontal_block&quot;</span><span class="p">:</span>
            <span class="c1"># End recursion, by doing an extra regular block.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nested</span> <span class="o">=</span> <span class="n">horizontal_block_factory</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported deepest_inner value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">deepest_inner</span><span class="p">)</span>
            <span class="p">)</span>

<div class="viewcode-block" id="UNetBlock.forward"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.UNetBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">horizontal_block_a</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nested</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concatenate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">horizontal_block_b</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="UNet"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.UNet">[docs]</a><span class="k">class</span> <span class="nc">UNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    UNet model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_channels : int</span>
<span class="sd">        Number of input channels.</span>
<span class="sd">    out_channels : int</span>
<span class="sd">        Number of output channels.</span>
<span class="sd">    initial_channels : int, optional</span>
<span class="sd">        Number of latent channels to output from the initial convolution</span>
<span class="sd">        facing the input layer. Default is `32`.</span>
<span class="sd">    bottleneck_channels : int, optional</span>
<span class="sd">        Number of channels to output from the first block, before the first</span>
<span class="sd">        unet downsampling step can occur. Default is the same as</span>
<span class="sd">        `initial_channels`.</span>
<span class="sd">    n_block : int, optional</span>
<span class="sd">        Number of blocks, both up and down. Default is `4`.</span>
<span class="sd">    unet_expansion_factor : int or float, optional</span>
<span class="sd">        Channel expansion factor between unet blocks. Default is `2`.</span>
<span class="sd">    expand_only_on_down : bool, optional</span>
<span class="sd">        Whether to only apply `unet_expansion_factor` on unet blocks which</span>
<span class="sd">        actually containg a down/up sampling component, and not on vanilla</span>
<span class="sd">        blocks. Default is `False`.</span>
<span class="sd">    blocks_per_downsample : int or sequence, optional</span>
<span class="sd">        Block interval between dowsampling steps in the unet. If this is</span>
<span class="sd">        a sequence, it corresponds to the number of blocks for each spatial</span>
<span class="sd">        dimension. Default is `1`.</span>
<span class="sd">    blocks_before_first_downsample : int, optional</span>
<span class="sd">        Number of blocks to use before and after the main unet structure.</span>
<span class="sd">        Must be at least `1`. Default is `1`.</span>
<span class="sd">    always_include_skip_connection : bool, optional</span>
<span class="sd">        If `True`, a skip connection is included between all blocks equally</span>
<span class="sd">        far from the start and end of the UNet. If `False`, skip connections</span>
<span class="sd">        are only used between downsampling and upsampling operations. Default</span>
<span class="sd">        is `True`.</span>
<span class="sd">    deepest_inner : {callable, &quot;horizontal_block&quot;, &quot;identity&quot;, None}, optional</span>
<span class="sd">        A layer which should be applied at the deepest part of the network,</span>
<span class="sd">        before the first upsampling step. The parameter should either be a</span>
<span class="sd">        pre-instantiated layer, or the string `&quot;horizontal_block&quot;`, to indicate</span>
<span class="sd">        an additional block as generated by the `horizontal_block_factory`.</span>
<span class="sd">        If it is the string `&quot;identity&quot;` or `None` (default), no additional</span>
<span class="sd">        layer is included at the deepest point before upsampling begins.</span>
<span class="sd">    intrablock_expansion : int or float, optional</span>
<span class="sd">        Channel expansion factor within inverse residual block. Default is `6`.</span>
<span class="sd">    se_reduction : int or float, optional</span>
<span class="sd">        Channel reduction factor within squeeze and excite block.</span>
<span class="sd">        Default is `4`.</span>
<span class="sd">    downsampling_modes : {&quot;max&quot;, &quot;avg&quot;, &quot;stride&quot;} or sequence, optional</span>
<span class="sd">        The downsampling mode to use. If this is a string, the same</span>
<span class="sd">        downsampling mode is used for every downsampling step. If it is</span>
<span class="sd">        a sequence, it should contain a string for each downsampling step.</span>
<span class="sd">        If the input sequence is too short, the final value will be used</span>
<span class="sd">        for all remaining downsampling steps. Default is `&quot;max&quot;`.</span>
<span class="sd">    upsampling_modes : str or sequence, optional</span>
<span class="sd">        The upsampling mode to use. If this is a string, it must be `&quot;conv&quot;`,</span>
<span class="sd">        or something supported by :class:`torch.nn.Upsample`; the same</span>
<span class="sd">        upsampling mode is used for every upsampling step. If it is</span>
<span class="sd">        a sequence, it should contain a string for each upsampling step.</span>
<span class="sd">        If the input sequence is too short, the final value will be used</span>
<span class="sd">        for all remaining upsampling steps. Default is `&quot;bilinear&quot;`.</span>
<span class="sd">    depthwise_separable_conv : bool, optional</span>
<span class="sd">        Whether to use depthwise separable convolutions in the MBConv block.</span>
<span class="sd">        Otherwise, the depth and pointwise convolutions are fused together</span>
<span class="sd">        into a regular convolution. Default is `True`.</span>
<span class="sd">    residual : bool, optional</span>
<span class="sd">        Whether to use a residual architecture for the MBConv blocks.</span>
<span class="sd">        Default is `True`.</span>
<span class="sd">    actfn : str, optional</span>
<span class="sd">        Name of the activation function to use. Default is `&quot;InplaceReLU&quot;`.</span>
<span class="sd">    kernel_size : int, optional</span>
<span class="sd">        Size of convolution kernel to use. Default is `5`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">initial_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">bottleneck_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_block</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">unet_expansion_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">expand_only_on_down</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">blocks_per_downsample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">blocks_before_first_downsample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">always_include_skip_connection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">deepest_inner</span><span class="o">=</span><span class="s2">&quot;identity&quot;</span><span class="p">,</span>
        <span class="n">intrablock_expansion</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
        <span class="n">se_reduction</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">downsampling_modes</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
        <span class="n">upsampling_modes</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
        <span class="n">depthwise_separable_conv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">residual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">actfn</span><span class="o">=</span><span class="s2">&quot;InplaceReLU&quot;</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">bottleneck_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">bottleneck_channels</span> <span class="o">=</span> <span class="n">initial_channels</span>

        <span class="n">blocks_before_first_downsample</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_pair</span><span class="p">(</span>
            <span class="n">blocks_before_first_downsample</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">b</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">blocks_before_first_downsample</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;An initial block is hard coded. Number of blocks before first&quot;</span>
                <span class="s2">&quot; downsample must be at least 1.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>

        <span class="n">actfn_factory</span> <span class="o">=</span> <span class="n">modules</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">str2actfnfactory</span><span class="p">(</span><span class="n">actfn</span><span class="p">)</span>

        <span class="n">horizontal_block_factory</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
            <span class="n">modules</span><span class="o">.</span><span class="n">MBConv</span><span class="p">,</span>
            <span class="n">expansion</span><span class="o">=</span><span class="n">intrablock_expansion</span><span class="p">,</span>
            <span class="n">se_reduction</span><span class="o">=</span><span class="n">se_reduction</span><span class="p">,</span>
            <span class="n">fused</span><span class="o">=</span><span class="ow">not</span> <span class="n">depthwise_separable_conv</span><span class="p">,</span>
            <span class="n">residual</span><span class="o">=</span><span class="n">residual</span><span class="p">,</span>
            <span class="n">actfn</span><span class="o">=</span><span class="n">actfn_factory</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initial_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">modules</span><span class="o">.</span><span class="n">Conv2dSame</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">initial_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">bottleneck_channels</span><span class="p">),</span>
            <span class="n">actfn_factory</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first_block</span> <span class="o">=</span> <span class="n">horizontal_block_factory</span><span class="p">(</span>
            <span class="n">bottleneck_channels</span><span class="p">,</span>
            <span class="n">bottleneck_channels</span><span class="p">,</span>
            <span class="n">expansion</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main_blocks</span> <span class="o">=</span> <span class="n">UNetBlock</span><span class="p">(</span>
            <span class="n">bottleneck_channels</span><span class="p">,</span>
            <span class="n">horizontal_block_factory</span><span class="p">,</span>
            <span class="n">n_block</span><span class="o">=</span><span class="n">n_block</span><span class="p">,</span>
            <span class="n">block_expansion_factor</span><span class="o">=</span><span class="n">unet_expansion_factor</span><span class="p">,</span>
            <span class="n">expand_only_on_down</span><span class="o">=</span><span class="n">expand_only_on_down</span><span class="p">,</span>
            <span class="n">blocks_per_downsample</span><span class="o">=</span><span class="n">blocks_per_downsample</span><span class="p">,</span>
            <span class="n">blocks_before_first_downsample</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span>
                <span class="n">b</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">blocks_before_first_downsample</span>
            <span class="p">),</span>
            <span class="n">always_include_skip_connection</span><span class="o">=</span><span class="n">always_include_skip_connection</span><span class="p">,</span>
            <span class="n">deepest_inner</span><span class="o">=</span><span class="n">deepest_inner</span><span class="p">,</span>
            <span class="n">downsampling_modes</span><span class="o">=</span><span class="n">downsampling_modes</span><span class="p">,</span>
            <span class="n">upsampling_modes</span><span class="o">=</span><span class="n">upsampling_modes</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_block</span> <span class="o">=</span> <span class="n">horizontal_block_factory</span><span class="p">(</span><span class="n">bottleneck_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

<div class="viewcode-block" id="UNet.forward"><a class="viewcode-back" href="../../../source/packages/echofilter.nn.html#echofilter.nn.unet.UNet.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Scott C. Lowe<br/>
  
      &copy; Copyright 2022, Scott C. Lowe.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>